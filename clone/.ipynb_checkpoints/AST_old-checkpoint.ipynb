{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "Java,\n",
    "C, C++,\n",
    "\n",
    "Go, C#,\n",
    "Python, PHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T10:52:23.671998Z",
     "start_time": "2020-10-23T10:52:23.668005Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def expand_dict(d, seq):\n",
    "    for i in d.keys():\n",
    "        if isinstance(d[i], dict):\n",
    "            seq.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T11:40:18.027189Z",
     "start_time": "2020-10-23T11:40:18.018242Z"
    }
   },
   "outputs": [],
   "source": [
    "# For Golang\n",
    "'''\n",
    "import os\n",
    "import json\n",
    "with os.popen('go run goblin.go -file \"ast test/goblin.go\"') as f:\n",
    "    d = json.loads(f.read())\n",
    "print(d)\n",
    "'''\n",
    "\n",
    "class Node_go(object):\n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        self.is_str = isinstance(node, str)  # str => 叶子节点 => 无孩子节点\n",
    "        self.token = self.get_token(node)\n",
    "        self.children = self.add_children()\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.is_str:\n",
    "            return True\n",
    "        return len(self.node.children) == 0\n",
    "\n",
    "    def get_token(self, node):\n",
    "        if self.is_str:\n",
    "            return self.node\n",
    "        import _ast\n",
    "        if isinstance(node, _ast.AST):\n",
    "            token = node.__class__.__name__\n",
    "        else:\n",
    "            try:\n",
    "                token = str(node)\n",
    "            except:\n",
    "                token = ''\n",
    "        return token\n",
    "\n",
    "    def iter_fields(self, node, exclude=[]):\n",
    "        \"\"\"\n",
    "        Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``\n",
    "        that is present on *node*.\n",
    "        \"\"\"\n",
    "        for field in [f for f in node._fields if f not in exclude]:\n",
    "            try:\n",
    "                yield getattr(node, field)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    def ori_children(self, root, exclude=[]):\n",
    "        import _ast\n",
    "        #if isinstance(root, str):\n",
    "        #    children = []\n",
    "        if isinstance(root, list):\n",
    "            children = root\n",
    "        elif isinstance(root, _ast.AST):\n",
    "            #children = [getattr(root, f) for f in root._fields if getattr(root, f)]\n",
    "            children = self.iter_fields(root, exclude)\n",
    "        elif isinstance(root, set):  # 猜测这条规则不会触发吧\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "        return list(expand(children))\n",
    "\n",
    "    def add_children(self):\n",
    "        if self.is_str:  # str => 叶子节点 => 无孩子节点\n",
    "            return []\n",
    "        if self.token in EXCLUDE_FIELDS.keys():\n",
    "            ef = EXCLUDE_FIELDS[self.token]\n",
    "        else:\n",
    "            ef = []\n",
    "        children = self.ori_children(self.node, ef)\n",
    "        return [Node_python(child) for child in children]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T08:18:24.006935Z",
     "start_time": "2020-12-23T08:18:23.990012Z"
    }
   },
   "outputs": [],
   "source": [
    "# For Golang\n",
    "def expand(nested_list):  # 生成器，用于展开嵌套的list\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            yield from expand(item)\n",
    "        elif item:\n",
    "            yield item\n",
    "            \n",
    "class Preprocessor_go():\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.max_token = len(vocab)\n",
    "        \n",
    "    '''\n",
    "    def file_to_ast(self, file):\n",
    "        import subprocess\n",
    "        import json\n",
    "        proc = subprocess.Popen(\"vendor/bin/php-parse -j {}\".format(file), shell=True, stdout=subprocess.PIPE)\n",
    "        script_response = proc.stdout.read()\n",
    "        ast = json.loads(script_response.decode('UTF-8'))\n",
    "        return ast\n",
    "    '''\n",
    "\n",
    "    def file_to_ast(self, filename):\n",
    "        import os\n",
    "        assert os.path.isfile(filename)\n",
    "        assert filename[-3:].lower() == '.go'\n",
    "        import json\n",
    "        with os.popen('go run goblin.go -file \"' + filename + '\"') as f:\n",
    "            d = json.loads(f.read())\n",
    "        ast = d['declarations']\n",
    "        return ast\n",
    "    \n",
    "    def get_functions(self, ast):\n",
    "        return [f for f in ast if f['type']=='function']\n",
    "\n",
    "    def get_function_name(self, function_ast):\n",
    "        return function_ast['name']['value']\n",
    "\n",
    "    def get_token(self, node):\n",
    "        if isinstance(node, dict):\n",
    "            if 'type' in node.keys():\n",
    "                token = node['type']\n",
    "            elif 'kind' in node.keys():\n",
    "                token = node['kind']\n",
    "            else:\n",
    "                token = node['value']\n",
    "        elif isinstance(node, list): # 不可能发生吧？\n",
    "            return ''\n",
    "        else:\n",
    "            try:\n",
    "                token = str(node)\n",
    "            except:\n",
    "                token = ''\n",
    "        return token\n",
    "            \n",
    "    def get_children(self, root, exclude=[]):\n",
    "        import _ast\n",
    "        #if isinstance(root, str):\n",
    "        #    children = []\n",
    "        if isinstance(root, list): # 猜测这条规则不会触发吧\n",
    "            children = root\n",
    "        elif isinstance(root, dict):\n",
    "            children = [root[k] for k in root.keys()]\n",
    "        elif isinstance(root, set):  # 猜测这条规则不会触发吧\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "        return list(expand(children))\n",
    "\n",
    "\n",
    "    def ast_to_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:  # 这里的每个node就是对应一行代码？\n",
    "            btree = self.replaced_by_index(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_index(self, node):\n",
    "        # 返回的形式：[node, children1, children2, ...]\n",
    "        # 一个大list，每个children又是一个子list\n",
    "        token = node.token\n",
    "        result = [self.vocab[token].index if token in self.vocab else self.max_token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_index(child))\n",
    "        return result\n",
    "    \n",
    "    def ast_to_token_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:\n",
    "            btree = self.replaced_by_token(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_token(self, node):\n",
    "        #result = [node.token if node.token in self.vocab else 'UNKNOWN']\n",
    "        result = [node.token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_token(child))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_blocks(self, node, block_seq):\n",
    "        name = self.get_token(node)\n",
    "        block_seq.append(Node_python(node))\n",
    "        if name in EXCLUDE_FIELDS.keys():\n",
    "            ef = [f for f in node._fields if f not in EXCLUDE_FIELDS[name]]\n",
    "            children = self.get_children(node, ef)\n",
    "            for child in children:\n",
    "                self.get_blocks(child, block_seq)\n",
    "    \n",
    "    '''\n",
    "    以下两个函数对ast进行先序遍历获得先序遍历的token序列，用于 word embedding 的训练\n",
    "    '''\n",
    "    def get_sequence(self, node, sequence):  # 获取先序遍历结果，同时为一些特殊代码块加上'End'\n",
    "        token, children = self.get_token(node), self.get_children(node)\n",
    "        sequence.append(token)\n",
    "\n",
    "        for child in children:\n",
    "            self.get_sequence(child, sequence)\n",
    "\n",
    "    def trans_to_sequences(self, ast):\n",
    "        # 这个用于生成token列表，用于 word embedding 的训练\n",
    "        sequence = []\n",
    "        self.get_sequence(ast, sequence)  # 从根节点开始先序遍历\n",
    "        return sequence\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    以下函数待定，只是为了打印出来看一下ast或者block之类的，方便调试\n",
    "    '''\n",
    "    def visit_block(self, block):\n",
    "        pass\n",
    "        \n",
    "    def visit_token_block(self, block):\n",
    "        pass\n",
    "    \n",
    "    def block_to_embedded(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T11:49:28.610518Z",
     "start_time": "2020-10-23T11:49:25.971354Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "preprocessor = Preprocessor_go(['1'])\n",
    "\n",
    "file_name = file_name = 'ast test/goblin.go'\n",
    "file_name = os.path.normpath(file_name)\n",
    "\n",
    "ast = preprocessor.file_to_ast(file_name)\n",
    "fun_asts = preprocessor.get_functions(ast)\n",
    "fun_names = [preprocessor.get_function_name(f) for f in fun_asts]\n",
    "\n",
    "seqence = [preprocessor.trans_to_sequences(f) for f in fun_asts]\n",
    "#blocks = [preprocessor.ast_to_block(f) for f in fun_asts]\n",
    "#token_blocks = [preprocessor.ast_to_token_block(f) for f in fun_asts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T11:49:47.862466Z",
     "start_time": "2020-10-23T11:49:47.858285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['function', 'if', 'expression', 'statement', 'expression', 'call', 'expression', 'binary', 'expression', 'binary', 'call', 'identifier', 'expression', 'ident', 'ident', 'pos', 'identifier', 'ident', 'ident', 'String', 'expression', 'call', '+', 'STRING', 'literal', 'STRING', '\": \"', 'expression', '+', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'reason', 'expression', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'panic', 'expression', 'call', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'ShouldPanic', 'block', 'define', 'statement', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'res', 'identifier', 'expression', 'identifier', 'ident', 'ident', '_', 'call', 'composite', 'map', 'identifier', 'type', 'identifier', 'ident', 'ident', 'string', 'type', 'map', 'interface', 'type', 'interface', 'literal', 'composite', 'key-value', 'STRING', 'literal', 'STRING', '\"error\"', 'expression', 'key-value', 'composite', 'map', 'identifier', 'type', 'identifier', 'ident', 'ident', 'string', 'type', 'map', 'interface', 'type', 'interface', 'literal', 'composite', 'key-value', 'STRING', 'literal', 'STRING', '\"type\"', 'expression', 'key-value', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'typ', 'key-value', 'STRING', 'literal', 'STRING', '\"info\"', 'expression', 'key-value', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'reason', 'identifier', 'expression', 'ident', 'ident', 'json', 'identifier', 'ident', 'ident', 'Marshal', 'expression', 'call', 'define', 'expression', 'statement', 'expression', 'call', 'identifier', 'expression', 'identifier', 'ident', 'ident', 'res', 'selector', 'ident', 'ident', 'Write', 'expression', 'identifier', 'expression', 'ident', 'ident', 'os', 'identifier', 'ident', 'ident', 'Stderr', 'selector', 'expression', 'call', 'statement', 'block', 'statement', 'if', 'expression', 'statement', 'expression', 'call', 'INT', 'literal', 'INT', '1', 'identifier', 'expression', 'ident', 'ident', 'os', 'identifier', 'ident', 'ident', 'Exit', 'expression', 'call', 'decl', 'ident', 'ident', 'Perish', 'field', 'identifier', 'type', 'ident', 'ident', 'token', 'identifier', 'ident', 'ident', 'Position', 'field', 'ident', 'ident', 'pos', 'field', 'identifier', 'type', 'identifier', 'ident', 'ident', 'string', 'field', 'ident', 'ident', 'typ', 'field', 'identifier', 'type', 'identifier', 'ident', 'ident', 'string', 'field', 'ident', 'ident', 'reason', 'function']\n"
     ]
    }
   ],
   "source": [
    "print(seqence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T12:38:53.270519Z",
     "start_time": "2020-10-23T12:38:53.257553Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': [{'body': [{'kind': 'statement',\n",
       "     'type': 'expression',\n",
       "     'value': {'arguments': [{'kind': 'binary',\n",
       "        'left': {'kind': 'binary',\n",
       "         'left': {'arguments': [],\n",
       "          'ellipsis': False,\n",
       "          'function': {'kind': 'expression',\n",
       "           'qualifier': {'kind': 'ident', 'value': 'pos'},\n",
       "           'type': 'identifier',\n",
       "           'value': {'kind': 'ident', 'value': 'String'}},\n",
       "          'kind': 'expression',\n",
       "          'type': 'call'},\n",
       "         'operator': '+',\n",
       "         'right': {'kind': 'literal', 'type': 'STRING', 'value': '\": \"'},\n",
       "         'type': 'expression'},\n",
       "        'operator': '+',\n",
       "        'right': {'kind': 'expression',\n",
       "         'type': 'identifier',\n",
       "         'value': {'kind': 'ident', 'value': 'reason'}},\n",
       "        'type': 'expression'}],\n",
       "      'ellipsis': False,\n",
       "      'function': {'kind': 'expression',\n",
       "       'type': 'identifier',\n",
       "       'value': {'kind': 'ident', 'value': 'panic'}},\n",
       "      'kind': 'expression',\n",
       "      'type': 'call'}}],\n",
       "   'condition': {'kind': 'expression',\n",
       "    'type': 'identifier',\n",
       "    'value': {'kind': 'ident', 'value': 'ShouldPanic'}},\n",
       "   'else': {'body': [{'kind': 'statement',\n",
       "      'left': [{'kind': 'expression',\n",
       "        'type': 'identifier',\n",
       "        'value': {'kind': 'ident', 'value': 'res'}},\n",
       "       {'kind': 'expression',\n",
       "        'type': 'identifier',\n",
       "        'value': {'kind': 'ident', 'value': '_'}}],\n",
       "      'right': [{'arguments': [{'declared': {'key': {'kind': 'type',\n",
       "            'type': 'identifier',\n",
       "            'value': {'kind': 'ident', 'value': 'string'}},\n",
       "           'kind': 'type',\n",
       "           'type': 'map',\n",
       "           'value': {'incomplete': False,\n",
       "            'kind': 'type',\n",
       "            'methods': [],\n",
       "            'type': 'interface'}},\n",
       "          'kind': 'literal',\n",
       "          'type': 'composite',\n",
       "          'values': [{'key': {'kind': 'literal',\n",
       "             'type': 'STRING',\n",
       "             'value': '\"error\"'},\n",
       "            'kind': 'expression',\n",
       "            'type': 'key-value',\n",
       "            'value': {'declared': {'key': {'kind': 'type',\n",
       "               'type': 'identifier',\n",
       "               'value': {'kind': 'ident', 'value': 'string'}},\n",
       "              'kind': 'type',\n",
       "              'type': 'map',\n",
       "              'value': {'incomplete': False,\n",
       "               'kind': 'type',\n",
       "               'methods': [],\n",
       "               'type': 'interface'}},\n",
       "             'kind': 'literal',\n",
       "             'type': 'composite',\n",
       "             'values': [{'key': {'kind': 'literal',\n",
       "                'type': 'STRING',\n",
       "                'value': '\"type\"'},\n",
       "               'kind': 'expression',\n",
       "               'type': 'key-value',\n",
       "               'value': {'kind': 'expression',\n",
       "                'type': 'identifier',\n",
       "                'value': {'kind': 'ident', 'value': 'typ'}}},\n",
       "              {'key': {'kind': 'literal', 'type': 'STRING', 'value': '\"info\"'},\n",
       "               'kind': 'expression',\n",
       "               'type': 'key-value',\n",
       "               'value': {'kind': 'expression',\n",
       "                'type': 'identifier',\n",
       "                'value': {'kind': 'ident', 'value': 'reason'}}}]}}]}],\n",
       "        'ellipsis': False,\n",
       "        'function': {'kind': 'expression',\n",
       "         'qualifier': {'kind': 'ident', 'value': 'json'},\n",
       "         'type': 'identifier',\n",
       "         'value': {'kind': 'ident', 'value': 'Marshal'}},\n",
       "        'kind': 'expression',\n",
       "        'type': 'call'}],\n",
       "      'type': 'define'},\n",
       "     {'kind': 'statement',\n",
       "      'type': 'expression',\n",
       "      'value': {'arguments': [{'kind': 'expression',\n",
       "         'type': 'identifier',\n",
       "         'value': {'kind': 'ident', 'value': 'res'}}],\n",
       "       'ellipsis': False,\n",
       "       'function': {'field': {'kind': 'ident', 'value': 'Write'},\n",
       "        'kind': 'expression',\n",
       "        'target': {'kind': 'expression',\n",
       "         'qualifier': {'kind': 'ident', 'value': 'os'},\n",
       "         'type': 'identifier',\n",
       "         'value': {'kind': 'ident', 'value': 'Stderr'}},\n",
       "        'type': 'selector'},\n",
       "       'kind': 'expression',\n",
       "       'type': 'call'}}],\n",
       "    'kind': 'statement',\n",
       "    'type': 'block'},\n",
       "   'init': None,\n",
       "   'kind': 'statement',\n",
       "   'type': 'if'},\n",
       "  {'kind': 'statement',\n",
       "   'type': 'expression',\n",
       "   'value': {'arguments': [{'kind': 'literal', 'type': 'INT', 'value': '1'}],\n",
       "    'ellipsis': False,\n",
       "    'function': {'kind': 'expression',\n",
       "     'qualifier': {'kind': 'ident', 'value': 'os'},\n",
       "     'type': 'identifier',\n",
       "     'value': {'kind': 'ident', 'value': 'Exit'}},\n",
       "    'kind': 'expression',\n",
       "    'type': 'call'}}],\n",
       " 'comments': [],\n",
       " 'kind': 'decl',\n",
       " 'name': {'kind': 'ident', 'value': 'Perish'},\n",
       " 'params': [{'declared-type': {'kind': 'type',\n",
       "    'qualifier': {'kind': 'ident', 'value': 'token'},\n",
       "    'type': 'identifier',\n",
       "    'value': {'kind': 'ident', 'value': 'Position'}},\n",
       "   'kind': 'field',\n",
       "   'names': [{'kind': 'ident', 'value': 'pos'}],\n",
       "   'tag': None},\n",
       "  {'declared-type': {'kind': 'type',\n",
       "    'type': 'identifier',\n",
       "    'value': {'kind': 'ident', 'value': 'string'}},\n",
       "   'kind': 'field',\n",
       "   'names': [{'kind': 'ident', 'value': 'typ'}],\n",
       "   'tag': None},\n",
       "  {'declared-type': {'kind': 'type',\n",
       "    'type': 'identifier',\n",
       "    'value': {'kind': 'ident', 'value': 'string'}},\n",
       "   'kind': 'field',\n",
       "   'names': [{'kind': 'ident', 'value': 'reason'}],\n",
       "   'tag': None}],\n",
       " 'results': None,\n",
       " 'type': 'function'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'body': [{'body': [{'kind': 'statement',\n",
    "     'type': 'expression',\n",
    "     'value': {'arguments': [{'kind': 'binary',\n",
    "        'left': {'kind': 'binary',\n",
    "         'left': {'arguments': [],\n",
    "          'ellipsis': False,\n",
    "          'function': {'kind': 'expression',\n",
    "           'qualifier': {'kind': 'ident', 'value': 'pos'},\n",
    "           'type': 'identifier',\n",
    "           'value': {'kind': 'ident', 'value': 'String'}},\n",
    "          'kind': 'expression',\n",
    "          'type': 'call'},\n",
    "         'operator': '+',\n",
    "         'right': {'kind': 'literal', 'type': 'STRING', 'value': '\": \"'},\n",
    "         'type': 'expression'},\n",
    "        'operator': '+',\n",
    "        'right': {'kind': 'expression',\n",
    "         'type': 'identifier',\n",
    "         'value': {'kind': 'ident', 'value': 'reason'}},\n",
    "        'type': 'expression'}],\n",
    "      'ellipsis': False,\n",
    "      'function': {'kind': 'expression',\n",
    "       'type': 'identifier',\n",
    "       'value': {'kind': 'ident', 'value': 'panic'}},\n",
    "      'kind': 'expression',\n",
    "      'type': 'call'}}],\n",
    "   'condition': {'kind': 'expression',\n",
    "    'type': 'identifier',\n",
    "    'value': {'kind': 'ident', 'value': 'ShouldPanic'}},\n",
    "   'else': {'body': [{'kind': 'statement',\n",
    "      'left': [{'kind': 'expression',\n",
    "        'type': 'identifier',\n",
    "        'value': {'kind': 'ident', 'value': 'res'}},\n",
    "       {'kind': 'expression',\n",
    "        'type': 'identifier',\n",
    "        'value': {'kind': 'ident', 'value': '_'}}],\n",
    "      'right': [{'arguments': [{'declared': {'key': {'kind': 'type',\n",
    "            'type': 'identifier',\n",
    "            'value': {'kind': 'ident', 'value': 'string'}},\n",
    "           'kind': 'type',\n",
    "           'type': 'map',\n",
    "           'value': {'incomplete': False,\n",
    "            'kind': 'type',\n",
    "            'methods': [],\n",
    "            'type': 'interface'}},\n",
    "          'kind': 'literal',\n",
    "          'type': 'composite',\n",
    "          'values': [{'key': {'kind': 'literal',\n",
    "             'type': 'STRING',\n",
    "             'value': '\"error\"'},\n",
    "            'kind': 'expression',\n",
    "            'type': 'key-value',\n",
    "            'value': {'declared': {'key': {'kind': 'type',\n",
    "               'type': 'identifier',\n",
    "               'value': {'kind': 'ident', 'value': 'string'}},\n",
    "              'kind': 'type',\n",
    "              'type': 'map',\n",
    "              'value': {'incomplete': False,\n",
    "               'kind': 'type',\n",
    "               'methods': [],\n",
    "               'type': 'interface'}},\n",
    "             'kind': 'literal',\n",
    "             'type': 'composite',\n",
    "             'values': [{'key': {'kind': 'literal',\n",
    "                'type': 'STRING',\n",
    "                'value': '\"type\"'},\n",
    "               'kind': 'expression',\n",
    "               'type': 'key-value',\n",
    "               'value': {'kind': 'expression',\n",
    "                'type': 'identifier',\n",
    "                'value': {'kind': 'ident', 'value': 'typ'}}},\n",
    "              {'key': {'kind': 'literal', 'type': 'STRING', 'value': '\"info\"'},\n",
    "               'kind': 'expression',\n",
    "               'type': 'key-value',\n",
    "               'value': {'kind': 'expression',\n",
    "                'type': 'identifier',\n",
    "                'value': {'kind': 'ident', 'value': 'reason'}}}]}}]}],\n",
    "        'ellipsis': False,\n",
    "        'function': {'kind': 'expression',\n",
    "         'qualifier': {'kind': 'ident', 'value': 'json'},\n",
    "         'type': 'identifier',\n",
    "         'value': {'kind': 'ident', 'value': 'Marshal'}},\n",
    "        'kind': 'expression',\n",
    "        'type': 'call'}],\n",
    "      'type': 'define'},\n",
    "     {'kind': 'statement',\n",
    "      'type': 'expression',\n",
    "      'value': {'arguments': [{'kind': 'expression',\n",
    "         'type': 'identifier',\n",
    "         'value': {'kind': 'ident', 'value': 'res'}}],\n",
    "       'ellipsis': False,\n",
    "       'function': {'field': {'kind': 'ident', 'value': 'Write'},\n",
    "        'kind': 'expression',\n",
    "        'target': {'kind': 'expression',\n",
    "         'qualifier': {'kind': 'ident', 'value': 'os'},\n",
    "         'type': 'identifier',\n",
    "         'value': {'kind': 'ident', 'value': 'Stderr'}},\n",
    "        'type': 'selector'},\n",
    "       'kind': 'expression',\n",
    "       'type': 'call'}}],\n",
    "    'kind': 'statement',\n",
    "    'type': 'block'},\n",
    "   'init': None,\n",
    "   'kind': 'statement',\n",
    "   'type': 'if'},\n",
    "  {'kind': 'statement',\n",
    "   'type': 'expression',\n",
    "   'value': {'arguments': [{'kind': 'literal', 'type': 'INT', 'value': '1'}],\n",
    "    'ellipsis': False,\n",
    "    'function': {'kind': 'expression',\n",
    "     'qualifier': {'kind': 'ident', 'value': 'os'},\n",
    "     'type': 'identifier',\n",
    "     'value': {'kind': 'ident', 'value': 'Exit'}},\n",
    "    'kind': 'expression',\n",
    "    'type': 'call'}}],\n",
    " 'comments': [],\n",
    " 'kind': 'decl',\n",
    " 'name': {'kind': 'ident', 'value': 'Perish'},\n",
    " 'params': [{'declared-type': {'kind': 'type',\n",
    "    'qualifier': {'kind': 'ident', 'value': 'token'},\n",
    "    'type': 'identifier',\n",
    "    'value': {'kind': 'ident', 'value': 'Position'}},\n",
    "   'kind': 'field',\n",
    "   'names': [{'kind': 'ident', 'value': 'pos'}],\n",
    "   'tag': None},\n",
    "  {'declared-type': {'kind': 'type',\n",
    "    'type': 'identifier',\n",
    "    'value': {'kind': 'ident', 'value': 'string'}},\n",
    "   'kind': 'field',\n",
    "   'names': [{'kind': 'ident', 'value': 'typ'}],\n",
    "   'tag': None},\n",
    "  {'declared-type': {'kind': 'type',\n",
    "    'type': 'identifier',\n",
    "    'value': {'kind': 'ident', 'value': 'string'}},\n",
    "   'kind': 'field',\n",
    "   'names': [{'kind': 'ident', 'value': 'reason'}],\n",
    "   'tag': None}],\n",
    " 'results': None,\n",
    " 'type': 'function'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T11:50:03.879108Z",
     "start_time": "2020-12-28T11:50:03.868138Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# For Python\n",
    "#Logic1 = ['For', 'AsyncFor', 'While', 'If', 'With', 'AsyncWith', 'Try']\n",
    "#Logic2 = ['FunctionDef', 'AsyncFunctionDef']\n",
    "EXCLUDE_FIELDS = {'FunctionDef': ['body', 'decorator_list'],\n",
    "                  'AsyncFunctionDef': ['body', 'decorator_list'],\n",
    "                  'For': ['body', 'orelse'],\n",
    "                  'AsyncFor': ['body', 'orelse'],\n",
    "                  'While': ['body', 'orelse'], \n",
    "                  'If': ['body', 'orelse'],\n",
    "                  'With': ['body'],\n",
    "                  'AsyncWith': ['body'],\n",
    "                  'Try': ['body', 'handlers', 'orelse', 'finalbody'],\n",
    "                  'ExceptHandler': ['body']\n",
    "                 }\n",
    "\n",
    "class Node_python(object):\n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        self.is_str = isinstance(node, str)  # str => 叶子节点 => 无孩子节点\n",
    "        self.token = self.get_token(node)\n",
    "        self.children = self.add_children()\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.is_str:\n",
    "            return True\n",
    "        return len(self.node.children) == 0\n",
    "\n",
    "    def get_token(self, node):\n",
    "        if self.is_str:\n",
    "            return self.node\n",
    "        import _ast\n",
    "        if isinstance(node, _ast.AST):\n",
    "            token = node.__class__.__name__\n",
    "        else:\n",
    "            try:\n",
    "                token = str(node)\n",
    "            except:\n",
    "                token = ''\n",
    "        return token\n",
    "\n",
    "    def iter_fields(self, node, exclude=[]):\n",
    "        \"\"\"\n",
    "        Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``\n",
    "        that is present on *node*.\n",
    "        \"\"\"\n",
    "        for field in [f for f in node._fields if f not in exclude]:\n",
    "            try:\n",
    "                yield getattr(node, field)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    def ori_children(self, root, exclude=[]):\n",
    "        import _ast\n",
    "        #if isinstance(root, str):\n",
    "        #    children = []\n",
    "        if isinstance(root, list):\n",
    "            children = root\n",
    "        elif isinstance(root, _ast.AST):\n",
    "            #children = [getattr(root, f) for f in root._fields if getattr(root, f)]\n",
    "            children = self.iter_fields(root, exclude)\n",
    "        elif isinstance(root, set):  # 猜测这条规则不会触发吧\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "        return list(expand(children))\n",
    "\n",
    "    def add_children(self):\n",
    "        if self.is_str:  # str => 叶子节点 => 无孩子节点\n",
    "            return []\n",
    "        if self.token in EXCLUDE_FIELDS.keys():\n",
    "            ef = EXCLUDE_FIELDS[self.token]\n",
    "        else:\n",
    "            ef = []\n",
    "        children = self.ori_children(self.node, ef)\n",
    "        return [Node_python(child) for child in children]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T11:50:05.822685Z",
     "start_time": "2020-12-28T11:50:05.792733Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def fun_cleanout(code, fun_pos, mode=None, comment_open_close_pattern=None, comment_inline_pattern=None):\n",
    "    if mode is None:  # 只清除结尾多余的空行\n",
    "        pass\n",
    "    elif mode == 'tailer_comment':  # 只清除结尾多余的空行和注释\n",
    "        pass\n",
    "    elif mode = 'comment': # 清除所有的注释\n",
    "        pass\n",
    "    elif mode = 'all':  # 清除所有注释和空行（紧凑形式）\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "def expand(nested_list):  # 生成器，用于展开嵌套的list\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            #for sub_item in expand(item):\n",
    "            #    yield sub_item\n",
    "            yield from expand(item)\n",
    "        elif item:\n",
    "            yield item\n",
    "\n",
    "# For Python\n",
    "class Preprocessor_python():\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.max_token = len(vocab)\n",
    "    \n",
    "    '''\n",
    "    以下5个是从file到function_ast，也就是把一个文件中代码解析成AST并拆分出各个函数\n",
    "    '''\n",
    "    def file_to_code(self, filename):\n",
    "        import os\n",
    "        assert os.path.isfile(filename)\n",
    "        assert filename[-3:].lower() == '.py'\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "                code = f.read()\n",
    "            return code\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def file_to_ast(self, file):\n",
    "        ast = self.code_to_ast(self.file_to_code(file))\n",
    "        return ast\n",
    "    \n",
    "    def code_to_ast(self, code):\n",
    "        from Lib import ast as python_ast\n",
    "        ast = python_ast.parse(code)\n",
    "        return ast\n",
    "        \n",
    "    def get_functions(self, ast):\n",
    "        function_asts = []\n",
    "        for c in ast.body:\n",
    "            if c.__class__.__name__ == 'FunctionDef':\n",
    "                function_asts.append(c)\n",
    "            elif c.__class__.__name__ == 'ClassDef':\n",
    "                function_asts.extend(self.get_functions(c))\n",
    "        return function_asts\n",
    "\n",
    "    def get_function_name(self, function_ast):\n",
    "        return function_ast.name\n",
    "    \n",
    "    def extract_functions(self, code):\n",
    "        '''\n",
    "        输入代码，输出两个list：一个是函数的ast，一个是函数起止行\n",
    "        '''\n",
    "        import ast\n",
    "        tree = None\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            return None, None\n",
    "\n",
    "        linecount = code.count(\"\\n\")\n",
    "        if not code.endswith(\"\\n\"):\n",
    "            linecount += 1\n",
    "\n",
    "        function_nodes = []\n",
    "        function_pos = []\n",
    "\n",
    "        for index, stmt in enumerate(tree.body):\n",
    "            if isinstance(stmt, ast.ClassDef):\n",
    "                for idx, s in enumerate(stmt.body):\n",
    "                    if isinstance(s, ast.FunctionDef):\n",
    "                        start_lineno =  s.lineno\n",
    "                        if idx == len(stmt.body)-1:\n",
    "                            # this is the last one in stmt.body\n",
    "                            if index == len(tree.body)-1:\n",
    "                                # also the last stmt in tree.body\n",
    "                                end_lineno = linecount\n",
    "                            else:\n",
    "                                # but not the last stmt in tree.body\n",
    "                                end_lineno =  tree.body[index+1].lineno-1\n",
    "                        else:\n",
    "                            #not the last one in stmt.body\n",
    "                            end_lineno = stmt.body[idx+1].lineno-1\n",
    "                        function_nodes.append(s)\n",
    "                        function_pos.append((start_lineno, end_lineno))\n",
    "\n",
    "            if isinstance(stmt, ast.FunctionDef):\n",
    "                start_lineno =  stmt.lineno\n",
    "                if index == len(tree.body)-1:\n",
    "                    # the last stmt in tree.body\n",
    "                    end_lineno = linecount\n",
    "                else:\n",
    "                    end_lineno = tree.body[index+1].lineno-1\n",
    "                function_nodes.append(s)\n",
    "                function_pos.append((start_lineno, end_lineno))\n",
    "\n",
    "        return function_nodes, function_pos\n",
    "    \n",
    "\n",
    "    '''\n",
    "    以下两个函数分别获取节点token和孩子节点，是后续其他操作的基础\n",
    "    '''\n",
    "    def get_token(self, node):\n",
    "        import _ast\n",
    "        if isinstance(node, str):\n",
    "            token = node\n",
    "        elif isinstance(node, _ast.AST):\n",
    "            token = node.__class__.__name__\n",
    "        else:\n",
    "            try:\n",
    "                token = str(node)\n",
    "            except:\n",
    "                token = ''\n",
    "        return token\n",
    "        \n",
    "    def iter_fields(self, node, exclude=[]):\n",
    "        \"\"\"\n",
    "        Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``\n",
    "        that is present on *node*.\n",
    "        \"\"\"\n",
    "        for field in [f for f in node._fields if f not in exclude]:\n",
    "            try:\n",
    "                yield getattr(node, field)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    def get_children(self, root, exclude=[]):\n",
    "        import _ast\n",
    "        #if isinstance(root, str):\n",
    "        #    children = []\n",
    "        if isinstance(root, list):\n",
    "            children = root\n",
    "        elif isinstance(root, _ast.AST):\n",
    "            #children = [getattr(root, f) for f in root._fields if getattr(root, f)]\n",
    "            children = self.iter_fields(root, exclude)\n",
    "        elif isinstance(root, set):  # 猜测这条规则不会触发吧\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "        return list(expand(children))\n",
    "\n",
    "    \n",
    "    '''\n",
    "    以下函数，都是把ast变成ASTNN的输入结构，但是前两个使用token index，后两个使用token本身\n",
    "    主要用前两个\n",
    "    后两个是为了打印出来方便调试\n",
    "    '''\n",
    "    def ast_to_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:  # 这里的每个node就是对应一行代码？\n",
    "            btree = self.replaced_by_index(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_index(self, node):\n",
    "        # 返回的形式：[node, children1, children2, ...]\n",
    "        # 一个大list，每个children又是一个子list\n",
    "        token = node.token\n",
    "        result = [self.vocab[token].index if token in self.vocab else self.max_token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_index(child))\n",
    "        return result\n",
    "    \n",
    "    def ast_to_token_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:\n",
    "            btree = self.replaced_by_token(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_token(self, node):\n",
    "        #result = [node.token if node.token in self.vocab else 'UNKNOWN']\n",
    "        result = [node.token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_token(child))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    最复杂的东东，根据当前的 node 获得一个或多个 Node_python 并添加到 block_seq 里面\n",
    "    block_seq.append 的必定是一个 Node_python，可以猜测 Node_python 是一个把 ast.Node 转化成自定义的节点类\n",
    "    '''\n",
    "    def get_blocks(self, node, block_seq):\n",
    "        name = self.get_token(node)\n",
    "        block_seq.append(Node_python(node))\n",
    "        if name in EXCLUDE_FIELDS.keys():\n",
    "            ef = [f for f in node._fields if f not in EXCLUDE_FIELDS[name]]\n",
    "            children = self.get_children(node, ef)\n",
    "            for child in children:\n",
    "                self.get_blocks(child, block_seq)\n",
    "    \n",
    "    '''\n",
    "    以下两个函数对ast进行先序遍历获得先序遍历的token序列，用于 word embedding 的训练\n",
    "    '''\n",
    "    def get_sequence(self, node, sequence):  # 获取先序遍历结果，同时为一些特殊代码块加上'End'\n",
    "        token, children = self.get_token(node), self.get_children(node)\n",
    "        sequence.append(token)\n",
    "\n",
    "        for child in children:\n",
    "            self.get_sequence(child, sequence)\n",
    "\n",
    "    def trans_to_sequences(self, ast):\n",
    "        # 这个用于生成token列表，用于 word embedding 的训练\n",
    "        sequence = []\n",
    "        self.get_sequence(ast, sequence)  # 从根节点开始先序遍历\n",
    "        return sequence\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    以下函数待定，只是为了打印出来看一下ast或者block之类的，方便调试\n",
    "    '''\n",
    "    def visit_block(self, block):\n",
    "        pass\n",
    "        \n",
    "    def visit_token_block(self, block):\n",
    "        pass\n",
    "    \n",
    "    def block_to_embedded(self):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T05:41:53.583271Z",
     "start_time": "2020-10-18T05:41:53.569309Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import _ast\n",
    "def iter_fields(node):\n",
    "    \"\"\"\n",
    "    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``\n",
    "    that is present on *node*.\n",
    "    \"\"\"\n",
    "    for field in node._fields:\n",
    "        try:\n",
    "            yield field, getattr(node, field)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def iter_child_nodes(node):\n",
    "    \"\"\"\n",
    "    Yield all direct child nodes of *node*, that is, all fields that are nodes\n",
    "    and all items of fields that are lists of nodes.\n",
    "    \"\"\"\n",
    "    import _ast\n",
    "    for name, field in iter_fields(node):\n",
    "        if isinstance(field, _ast.AST):\n",
    "            yield field\n",
    "        elif isinstance(field, list):\n",
    "            for item in field:\n",
    "                if isinstance(item, _ast.AST):\n",
    "                    yield item\n",
    "                    \n",
    "def walk(node):\n",
    "    \"\"\"\n",
    "    Recursively yield all descendant nodes in the tree starting at *node*\n",
    "    (including *node* itself), in no specified order.  This is useful if you\n",
    "    only want to modify nodes in place and don't care about the context.\n",
    "    \"\"\"\n",
    "    from collections import deque\n",
    "    todo = deque([node])\n",
    "    while todo:\n",
    "        node = todo.popleft()\n",
    "        todo.extend(iter_child_nodes(node))\n",
    "        yield node\n",
    "        \n",
    "        \n",
    "def ast_dump(node, annotate_fields=True, include_attributes=False, *, indent=None):\n",
    "    \"\"\"\n",
    "    Return a formatted dump of the tree in node.  This is mainly useful for\n",
    "    debugging purposes.  If annotate_fields is true (by default),\n",
    "    the returned string will show the names and the values for fields.\n",
    "    If annotate_fields is false, the result string will be more compact by\n",
    "    omitting unambiguous field names.  Attributes such as line\n",
    "    numbers and column offsets are not dumped by default.  If this is wanted,\n",
    "    include_attributes can be set to true.  If indent is a non-negative\n",
    "    integer or string, then the tree will be pretty-printed with that indent\n",
    "    level. None (the default) selects the single line representation.\n",
    "    \"\"\"\n",
    "    def _format(node, level=0):\n",
    "        if indent is not None:\n",
    "            level += 1\n",
    "            prefix = '\\n' + indent * level\n",
    "            sep = ',\\n' + indent * level\n",
    "        else:\n",
    "            prefix = ''\n",
    "            sep = ', '\n",
    "        if isinstance(node, _ast.AST):\n",
    "            cls = type(node)\n",
    "            args = []\n",
    "            allsimple = True\n",
    "            keywords = annotate_fields\n",
    "            for name in node._fields:\n",
    "                try:\n",
    "                    value = getattr(node, name)\n",
    "                except AttributeError:\n",
    "                    keywords = True\n",
    "                    continue\n",
    "                if value is None and getattr(cls, name, ...) is None:\n",
    "                    keywords = True\n",
    "                    continue\n",
    "                value, simple = _format(value, level)\n",
    "                allsimple = allsimple and simple\n",
    "                if keywords:\n",
    "                    args.append('%s=%s' % (name, value))\n",
    "                else:\n",
    "                    args.append(value)\n",
    "            if include_attributes and node._attributes:\n",
    "                for name in node._attributes:\n",
    "                    try:\n",
    "                        value = getattr(node, name)\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                    if value is None and getattr(cls, name, ...) is None:\n",
    "                        continue\n",
    "                    value, simple = _format(value, level)\n",
    "                    allsimple = allsimple and simple\n",
    "                    args.append('%s=%s' % (name, value))\n",
    "            if allsimple and len(args) <= 3:\n",
    "                return '%s(%s)' % (node.__class__.__name__, ', '.join(args)), not args\n",
    "            return '%s(%s%s)' % (node.__class__.__name__, prefix, sep.join(args)), False\n",
    "        elif isinstance(node, list):\n",
    "            if not node:\n",
    "                return '[]', True\n",
    "            return '[%s%s]' % (prefix, sep.join(_format(x, level)[0] for x in node)), False\n",
    "        return repr(node), True\n",
    "\n",
    "    if not isinstance(node, _ast.AST):\n",
    "        raise TypeError('expected AST, got %r' % node.__class__.__name__)\n",
    "    if indent is not None and not isinstance(indent, str):\n",
    "        indent = ' ' * indent\n",
    "    return _format(node)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T11:50:15.545577Z",
     "start_time": "2020-12-28T11:50:13.247508Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Lib import ast as python_ast\n",
    "import os\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "root = 'data/'\n",
    "lang = 'java'\n",
    "\n",
    "word2vec = Word2Vec.load(root+lang+\"/train/embedding/node_w2v_128\").wv\n",
    "preprocessor = Preprocessor_python(word2vec.vocab)\n",
    "\n",
    "file_name = file_name = 'ast test/python test 1.py'\n",
    "file_name = os.path.normpath(file_name)\n",
    "\n",
    "code = preprocessor.file_to_code(file_name)\n",
    "ast = preprocessor.code_to_ast(code)\n",
    "fun_asts = preprocessor.get_functions(ast)\n",
    "fun_names = [preprocessor.get_function_name(f) for f in fun_asts]\n",
    "\n",
    "\n",
    "seqence = [preprocessor.trans_to_sequences(f) for f in fun_asts]\n",
    "blocks = [preprocessor.ast_to_block(f) for f in fun_asts]\n",
    "token_blocks = [preprocessor.ast_to_token_block(f) for f in fun_asts]\n",
    "\n",
    "nodes, pos = preprocessor.extract_functions(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T11:51:28.932823Z",
     "start_time": "2020-12-28T11:51:28.927864Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 13),\n",
       " (14, 59),\n",
       " (60, 93),\n",
       " (94, 160),\n",
       " (162, 194),\n",
       " (195, 200),\n",
       " (201, 204),\n",
       " (205, 213),\n",
       " (214, 315),\n",
       " (316, 366),\n",
       " (367, 409),\n",
       " (410, 527),\n",
       " (539, 548),\n",
       " (557, 560),\n",
       " (561, 568)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T11:39:07.372632Z",
     "start_time": "2020-10-23T11:39:07.360638Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['FunctionDef', ['get_device'], ['arguments']],\n",
       " ['If',\n",
       "  ['Call',\n",
       "   ['Attribute',\n",
       "    ['Attribute', ['Name', ['torch'], ['Load']], ['cuda'], ['Load']],\n",
       "    ['is_available'],\n",
       "    ['Load']]]],\n",
       " ['If',\n",
       "  ['Compare',\n",
       "   ['Call',\n",
       "    ['Attribute',\n",
       "     ['Attribute', ['Name', ['torch'], ['Load']], ['cuda'], ['Load']],\n",
       "     ['get_device_name'],\n",
       "     ['Load']],\n",
       "    ['Constant']],\n",
       "   ['Eq'],\n",
       "   ['Constant', ['GeForce GT 730']]]],\n",
       " ['Assign', ['Name', ['device'], ['Store']], ['Constant', ['cpu']]],\n",
       " ['Assign', ['Name', ['device'], ['Store']], ['Constant', ['cuda']]],\n",
       " ['Assign', ['Name', ['device'], ['Store']], ['Constant', ['cpu']]],\n",
       " ['Return',\n",
       "  ['Call',\n",
       "   ['Attribute', ['Name', ['torch'], ['Load']], ['device'], ['Load']],\n",
       "   ['Name', ['device'], ['Load']]]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(token_blocks[-3]))\n",
    "token_blocks[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T05:44:01.561067Z",
     "start_time": "2020-10-18T05:44:01.557077Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionDef(\n",
      "    name='get_device',\n",
      "    args=arguments(\n",
      "        posonlyargs=[],\n",
      "        args=[],\n",
      "        vararg=None,\n",
      "        kwonlyargs=[],\n",
      "        kw_defaults=[],\n",
      "        kwarg=None,\n",
      "        defaults=[]),\n",
      "    body=[\n",
      "        If(\n",
      "            test=Call(\n",
      "                func=Attribute(\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='torch', ctx=Load()),\n",
      "                        attr='cuda',\n",
      "                        ctx=Load()),\n",
      "                    attr='is_available',\n",
      "                    ctx=Load()),\n",
      "                args=[],\n",
      "                keywords=[]),\n",
      "            body=[\n",
      "                If(\n",
      "                    test=Compare(\n",
      "                        left=Call(\n",
      "                            func=Attribute(\n",
      "                                value=Attribute(\n",
      "                                    value=Name(id='torch', ctx=Load()),\n",
      "                                    attr='cuda',\n",
      "                                    ctx=Load()),\n",
      "                                attr='get_device_name',\n",
      "                                ctx=Load()),\n",
      "                            args=[\n",
      "                                Constant(value=0, kind=None)],\n",
      "                            keywords=[]),\n",
      "                        ops=[\n",
      "                            Eq()],\n",
      "                        comparators=[\n",
      "                            Constant(value='GeForce GT 730', kind=None)]),\n",
      "                    body=[\n",
      "                        Assign(\n",
      "                            targets=[\n",
      "                                Name(id='device', ctx=Store())],\n",
      "                            value=Constant(value='cpu', kind=None),\n",
      "                            type_comment=None)],\n",
      "                    orelse=[\n",
      "                        Assign(\n",
      "                            targets=[\n",
      "                                Name(id='device', ctx=Store())],\n",
      "                            value=Constant(value='cuda', kind=None),\n",
      "                            type_comment=None)])],\n",
      "            orelse=[\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='device', ctx=Store())],\n",
      "                    value=Constant(value='cpu', kind=None),\n",
      "                    type_comment=None)]),\n",
      "        Return(\n",
      "            value=Call(\n",
      "                func=Attribute(\n",
      "                    value=Name(id='torch', ctx=Load()),\n",
      "                    attr='device',\n",
      "                    ctx=Load()),\n",
      "                args=[\n",
      "                    Name(id='device', ctx=Load())],\n",
      "                keywords=[]))],\n",
      "    decorator_list=[],\n",
      "    returns=None,\n",
      "    type_comment=None)\n"
     ]
    }
   ],
   "source": [
    "#for i in walk(fun_asts[-3]):\n",
    "#    print(i, preprocessor.get_token(i), i._fields)\n",
    "print(ast_dump(fun_asts[-3], indent=4))\n",
    "#python_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T05:41:54.799020Z",
     "start_time": "2020-10-18T05:41:54.795030Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FunctionDef', 'get_device', 'arguments', 'If', 'Call', 'Attribute', 'Attribute', 'Name', 'torch', 'Load', 'cuda', 'Load', 'is_available', 'Load', 'If', 'Compare', 'Call', 'Attribute', 'Attribute', 'Name', 'torch', 'Load', 'cuda', 'Load', 'get_device_name', 'Load', 'Constant', 'Eq', 'Constant', 'GeForce GT 730', 'Assign', 'Name', 'device', 'Store', 'Constant', 'cpu', 'Assign', 'Name', 'device', 'Store', 'Constant', 'cuda', 'Assign', 'Name', 'device', 'Store', 'Constant', 'cpu', 'Return', 'Call', 'Attribute', 'Name', 'torch', 'Load', 'device', 'Load', 'Name', 'device', 'Load']\n"
     ]
    }
   ],
   "source": [
    "print(seqence[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:39:00.824439Z",
     "start_time": "2020-12-28T12:39:00.814496Z"
    }
   },
   "outputs": [],
   "source": [
    "# For C++\n",
    "class Node_cpp(object):\n",
    "    def __init__(self, node, add_children = True):\n",
    "        self.node = node\n",
    "        self.is_str = isinstance(self.node, str)\n",
    "        self.token = self.get_token()\n",
    "        if add_children:\n",
    "            self.children = self.add_children()\n",
    "        else:\n",
    "            self.children = []\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.is_str:\n",
    "            return True\n",
    "        return len(self.node.children()) == 0\n",
    "\n",
    "    def get_token(self, lower=True):\n",
    "        if self.is_str:\n",
    "            return self.node\n",
    "        name = self.node.__class__.__name__\n",
    "        token = name\n",
    "        is_name = False\n",
    "        if self.is_leaf():\n",
    "            attr_names = self.node.attr_names\n",
    "            if attr_names:\n",
    "                if 'names' in attr_names:\n",
    "                    token = self.node.names[0]\n",
    "                elif 'name' in attr_names:\n",
    "                    token = self.node.name\n",
    "                    is_name = True\n",
    "                else:\n",
    "                    token = self.node.value\n",
    "            else:\n",
    "                token = name\n",
    "        else:\n",
    "            if name == 'TypeDecl':\n",
    "                token = self.node.declname\n",
    "            if self.node.attr_names:\n",
    "                attr_names = self.node.attr_names\n",
    "                if 'op' in attr_names:\n",
    "                    if self.node.op[0] == 'p':\n",
    "                        token = self.node.op[1:]\n",
    "                    else:\n",
    "                        token = self.node.op\n",
    "        if token == None:\n",
    "            token = name\n",
    "        if lower and is_name:\n",
    "            token = token.lower()\n",
    "        return token\n",
    "\n",
    "    def add_children(self):\n",
    "        if self.is_str:\n",
    "            return []\n",
    "        children = self.node.children()\n",
    "        if self.token in ['FuncDef', 'If', 'While', 'DoWhile']:\n",
    "            return [Node_cpp(children[0][1])]\n",
    "        elif self.token == 'For':\n",
    "            return [Node_cpp(children[c][1]) for c in range(0, len(children)-1)]\n",
    "        else:\n",
    "            return [Node_cpp(child) for _, child in children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:42:24.721151Z",
     "start_time": "2020-12-28T12:42:24.697215Z"
    }
   },
   "outputs": [],
   "source": [
    "# For C++\n",
    "class Preprocessor_cpp():\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.max_token = len(vocab)\n",
    "    \n",
    "    '''\n",
    "    以下5个是从file到function_ast，也就是把一个文件中代码解析成AST并拆分出各个函数\n",
    "    '''\n",
    "    def file_to_code(self, filename):\n",
    "        import os\n",
    "        assert os.path.isfile(filename)\n",
    "        assert filename[-4:].lower()=='.cpp'\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "                code = f.read()\n",
    "            return code\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def file_to_ast(self, file):\n",
    "        #ast = self.code_to_ast(self.file_to_code(file))\n",
    "        from pycparser import parse_file\n",
    "        ast = parse_file(file, use_cpp=False,\n",
    "            cpp_path='cpp'),\n",
    "            #cpp_args=r'-Iutils/fake_libc_include')\n",
    "        return ast\n",
    "    \n",
    "    def code_to_ast(self, code):\n",
    "        from pycparser import c_parser\n",
    "        parser = c_parser.CParser()\n",
    "        ast = parser.parse(code)\n",
    "        return ast\n",
    "        '''\n",
    "        try:\n",
    "            from pycparser import c_parser\n",
    "            parser = c_parser.CParser()\n",
    "            ast = parser.parse(code)\n",
    "            return ast\n",
    "        except:\n",
    "            return None\n",
    "        '''\n",
    "\n",
    "\n",
    "    def get_functions(self, ast):\n",
    "        # 只要 function\n",
    "        return [func_ast for func_ast in ast.ext if func_ast.__class__.__name__ == 'FuncDef']\n",
    "\n",
    "    def get_function_name(self, function_ast):\n",
    "        return function_ast.decl.name\n",
    "    \n",
    "    def extract_functions(self, code):\n",
    "        '''\n",
    "        输入代码，输出两个list：一个是函数的ast，一个是函数起止行\n",
    "        '''\n",
    "        import clang\n",
    "        import clang.cindex\n",
    "        from clang.cindex import CursorKind\n",
    "        \n",
    "        \n",
    "        function_pos = []\n",
    "        function_nodes = []\n",
    "        try:\n",
    "            index = clang.cindex.Index.create()\n",
    "            tu = index.parse(path='0.cpp', unsaved_files=[('0.cpp',code)])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            return None, None\n",
    "\n",
    "        AST_root_node= tu.cursor\n",
    "        file_string_split = code.split('\\n')\n",
    "        linecount = code.count(\"\\n\")\n",
    "        if not code.endswith(\"\\n\"):\n",
    "            linecount += 1\n",
    "        ast_list = list(AST_root_node.get_children())\n",
    "\n",
    "        for idx, cur in enumerate(ast_list):\n",
    "            if cur.kind == CursorKind.FUNCTION_DECL:\n",
    "                start_lineno = cur.location.line\n",
    "                if idx == len(ast_list) - 1:\n",
    "                    end_lineno = linecount\n",
    "                else:\n",
    "                    end_lineno = ast_list[idx+1].location.line - 1\n",
    "                function_nodes.append(cur)\n",
    "                function_pos.append((start_lineno, end_lineno))\n",
    "                \n",
    "            elif cur.kind == CursorKind.CLASS_DECL:\n",
    "                ast_list_in_class = list(cur.get_children())\n",
    "                for idx_in_class, cur_in_class in enumerate(ast_list_in_class):\n",
    "                    if cur_in_class.kind == CursorKind.CXX_METHOD:\n",
    "                        start_lineno = cur_in_class.location.line\n",
    "                        if idx_in_class == len(ast_list_in_class) - 1: \n",
    "                            if idx == len(ast_list) - 1:\n",
    "                                end_lineno = linecount\n",
    "                            else:\n",
    "                                end_lineno = ast_list[idx+1].location.line - 1\n",
    "                            for lineno in range(end_lineno-1, 0, -1):\n",
    "                                if file_string_split[lineno] and file_string_split[lineno][0]=='}':\n",
    "                                    end_lineno = lineno\n",
    "                                    break\n",
    "                        else:\n",
    "                            end_lineno = ast_list_in_class[idx_in_class+1].location.line - 1\n",
    "                        function_nodes.append(cur_in_class)\n",
    "                        function_pos.append((start_lineno, end_lineno))\n",
    "\n",
    "        return function_nodes, function_pos\n",
    "\n",
    "    \n",
    "    '''\n",
    "    以下函数，都是把ast变成ASTNN的输入结构，但是前两个使用token index，后两个使用token本身\n",
    "    主要用前两个\n",
    "    后两个是为了打印出来方便调试\n",
    "    '''\n",
    "    def ast_to_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:  # 这里的每个node就是对应一行代码？\n",
    "            btree = self.replaced_by_index(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_index(self, node):\n",
    "        # 返回的形式：[node, children1, children2, ...]\n",
    "        # 一个大list，每个children又是一个子list\n",
    "        token = node.token\n",
    "        result = [self.vocab[token].index if token in self.vocab else self.max_token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_index(child))\n",
    "        return result\n",
    "    \n",
    "    def ast_to_token_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:\n",
    "            btree = self.replaced_by_token(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_token(self, node):\n",
    "        result = [node.token if node.token in self.vocab else 'UNKNOWN']\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_token(child))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    def get_blocks(self, node, block_seq):\n",
    "        children = node.children()\n",
    "        name = node.__class__.__name__\n",
    "        if name in ['FuncDef', 'If', 'For', 'While', 'DoWhile']:\n",
    "            block_seq.append(Node_cpp(node))\n",
    "            if name != 'For':\n",
    "                skip = 1\n",
    "            else:\n",
    "                skip = len(children) - 1\n",
    "\n",
    "            for i in range(skip, len(children)):\n",
    "                child = children[i][1]\n",
    "                if child.__class__.__name__ not in ['FuncDef', 'If', 'For', 'While', 'DoWhile', 'Compound']:\n",
    "                    block_seq.append(Node_cpp(child))\n",
    "                self.get_blocks(child, block_seq)\n",
    "        elif name == 'Compound':\n",
    "            block_seq.append(Node_cpp(name))\n",
    "            for _, child in node.children():\n",
    "                if child.__class__.__name__ not in ['If', 'For', 'While', 'DoWhile']:\n",
    "                    block_seq.append(Node_cpp(child))\n",
    "                self.get_blocks(child, block_seq)\n",
    "            block_seq.append(Node_cpp('End'))\n",
    "        else:\n",
    "            for _, child in node.children():\n",
    "                self.get_blocks(child, block_seq)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    以下两个函数对ast进行先序遍历获得先序遍历的token序列，用于 word embedding 的训练\n",
    "    '''\n",
    "    def get_sequence(self, node, sequence):\n",
    "        current = Node_cpp(node, False)\n",
    "        sequence.append(current.get_token())\n",
    "        for _, child in node.children():\n",
    "            self.get_sequence(child, sequence)\n",
    "        if current.get_token().lower() == 'compound':\n",
    "            sequence.append('End')\n",
    "            # compound 代码段后面要加 End\n",
    "\n",
    "    def trans_to_sequences(self, ast):\n",
    "        # 这个用于生成token列表，用于 word embedding 的训练\n",
    "        sequence = []\n",
    "        self.get_sequence(ast, sequence)  # 从根节点开始先序遍历\n",
    "        return sequence\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    以下函数待定，只是为了打印出来看一下ast或者block之类的，方便调试\n",
    "    '''\n",
    "    def visit_block(self, block):\n",
    "        pass\n",
    "        \n",
    "    def visit_token_block(self, block):\n",
    "        block.show()\n",
    "    \n",
    "    def block_to_embedded(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:45:30.993473Z",
     "start_time": "2020-12-28T12:45:30.956571Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "root = 'data/'\n",
    "lang = 'java'\n",
    "\n",
    "word2vec = Word2Vec.load(root+lang+\"/train/embedding/node_w2v_128\").wv\n",
    "preprocessor = Preprocessor_cpp(word2vec.vocab)\n",
    "\n",
    "file_name = 'ast test/cpp test.cpp'\n",
    "file_name = os.path.normpath(file_name)\n",
    "\n",
    "#source = pd.read_pickle('D:/GitHub/astnn/classification/data/programs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:45:32.809391Z",
     "start_time": "2020-12-28T12:45:32.790413Z"
    }
   },
   "outputs": [],
   "source": [
    "code = preprocessor.file_to_code(file_name)\n",
    "#code = source[1][0]\n",
    "#ast = preprocessor.code_to_ast(code)\n",
    "#fun_asts = preprocessor.get_functions(ast)\n",
    "#fun_names = [preprocessor.get_function_name(f) for f in fun_asts]\n",
    "\n",
    "\n",
    "#seqence = [preprocessor.trans_to_sequences(f) for f in fun_asts]\n",
    "#blocks = [preprocessor.ast_to_block(f) for f in fun_asts]\n",
    "#token_blocks = [preprocessor.ast_to_token_block(f) for f in fun_asts]\n",
    "\n",
    "nodes, pos = preprocessor.extract_functions(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T13:35:05.438752Z",
     "start_time": "2020-12-28T13:35:05.391875Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main CursorKind.FUNCTION_DECL 4 5\n",
      " CursorKind.COMPOUND_STMT 6 1\n",
      " CursorKind.RETURN_STMT 13 5\n",
      " CursorKind.INTEGER_LITERAL 13 12\n",
      "A CursorKind.VAR_DECL 16 5\n",
      " CursorKind.BINARY_OPERATOR 16 9\n",
      " CursorKind.INTEGER_LITERAL 16 9\n",
      " CursorKind.INTEGER_LITERAL 16 11\n",
      "mainA CursorKind.FUNCTION_DECL 18 5\n",
      " CursorKind.COMPOUND_STMT 19 1\n",
      " CursorKind.DECL_STMT 20 5\n",
      "n CursorKind.VAR_DECL 20 9\n",
      "i CursorKind.VAR_DECL 20 11\n",
      "shuzu CursorKind.VAR_DECL 20 13\n",
      " CursorKind.INTEGER_LITERAL 20 19\n",
      "count1 CursorKind.VAR_DECL 20 24\n",
      " CursorKind.INTEGER_LITERAL 20 31\n",
      "count3 CursorKind.VAR_DECL 20 33\n",
      " CursorKind.INTEGER_LITERAL 20 40\n",
      "count2 CursorKind.VAR_DECL 20 42\n",
      " CursorKind.INTEGER_LITERAL 20 49\n",
      "count4 CursorKind.VAR_DECL 20 51\n",
      " CursorKind.INTEGER_LITERAL 20 58\n",
      "count5 CursorKind.VAR_DECL 20 60\n",
      " CursorKind.INTEGER_LITERAL 20 67\n",
      "count6 CursorKind.VAR_DECL 20 69\n",
      " CursorKind.INTEGER_LITERAL 20 76\n",
      " CursorKind.WHILE_STMT 22 5\n",
      " CursorKind.BINARY_OPERATOR 22 11\n",
      "n CursorKind.UNEXPOSED_EXPR 22 11\n",
      "n CursorKind.DECL_REF_EXPR 22 11\n",
      " CursorKind.INTEGER_LITERAL 22 14\n",
      " CursorKind.COMPOUND_STMT 22 18\n",
      " CursorKind.BINARY_OPERATOR 23 19\n",
      "n CursorKind.DECL_REF_EXPR 23 19\n",
      " CursorKind.BINARY_OPERATOR 23 21\n",
      "n CursorKind.UNEXPOSED_EXPR 23 21\n",
      "n CursorKind.DECL_REF_EXPR 23 21\n",
      " CursorKind.INTEGER_LITERAL 23 23\n",
      " CursorKind.UNARY_OPERATOR 24 19\n",
      "count1 CursorKind.DECL_REF_EXPR 24 19\n",
      " CursorKind.WHILE_STMT 26 23\n",
      " CursorKind.BINARY_OPERATOR 26 29\n",
      "n CursorKind.UNEXPOSED_EXPR 26 29\n",
      "n CursorKind.DECL_REF_EXPR 26 29\n",
      " CursorKind.INTEGER_LITERAL 26 32\n",
      " CursorKind.COMPOUND_STMT 26 35\n",
      " CursorKind.BINARY_OPERATOR 27 19\n",
      "n CursorKind.DECL_REF_EXPR 27 19\n",
      " CursorKind.BINARY_OPERATOR 27 21\n",
      "n CursorKind.UNEXPOSED_EXPR 27 21\n",
      "n CursorKind.DECL_REF_EXPR 27 21\n",
      " CursorKind.INTEGER_LITERAL 27 23\n",
      " CursorKind.UNARY_OPERATOR 28 19\n",
      "count2 CursorKind.DECL_REF_EXPR 28 19\n",
      " CursorKind.WHILE_STMT 30 23\n",
      " CursorKind.BINARY_OPERATOR 30 29\n",
      "n CursorKind.UNEXPOSED_EXPR 30 29\n",
      "n CursorKind.DECL_REF_EXPR 30 29\n",
      " CursorKind.INTEGER_LITERAL 30 32\n",
      " CursorKind.COMPOUND_STMT 30 35\n",
      " CursorKind.BINARY_OPERATOR 31 19\n",
      "n CursorKind.DECL_REF_EXPR 31 19\n",
      " CursorKind.BINARY_OPERATOR 31 21\n",
      "n CursorKind.UNEXPOSED_EXPR 31 21\n",
      "n CursorKind.DECL_REF_EXPR 31 21\n",
      " CursorKind.INTEGER_LITERAL 31 23\n",
      " CursorKind.UNARY_OPERATOR 32 19\n",
      "count3 CursorKind.DECL_REF_EXPR 32 19\n",
      " CursorKind.WHILE_STMT 34 23\n",
      " CursorKind.BINARY_OPERATOR 34 29\n",
      "n CursorKind.UNEXPOSED_EXPR 34 29\n",
      "n CursorKind.DECL_REF_EXPR 34 29\n",
      " CursorKind.INTEGER_LITERAL 34 32\n",
      " CursorKind.COMPOUND_STMT 34 35\n",
      " CursorKind.BINARY_OPERATOR 35 19\n",
      "n CursorKind.DECL_REF_EXPR 35 19\n",
      " CursorKind.BINARY_OPERATOR 35 21\n",
      "n CursorKind.UNEXPOSED_EXPR 35 21\n",
      "n CursorKind.DECL_REF_EXPR 35 21\n",
      " CursorKind.INTEGER_LITERAL 35 23\n",
      " CursorKind.UNARY_OPERATOR 36 19\n",
      "count4 CursorKind.DECL_REF_EXPR 36 19\n",
      " CursorKind.WHILE_STMT 37 24\n",
      " CursorKind.BINARY_OPERATOR 37 30\n",
      "n CursorKind.UNEXPOSED_EXPR 37 30\n",
      "n CursorKind.DECL_REF_EXPR 37 30\n",
      " CursorKind.INTEGER_LITERAL 37 33\n",
      " CursorKind.COMPOUND_STMT 37 35\n",
      " CursorKind.BINARY_OPERATOR 38 19\n",
      "n CursorKind.DECL_REF_EXPR 38 19\n",
      " CursorKind.BINARY_OPERATOR 38 21\n",
      "n CursorKind.UNEXPOSED_EXPR 38 21\n",
      "n CursorKind.DECL_REF_EXPR 38 21\n",
      " CursorKind.INTEGER_LITERAL 38 23\n",
      " CursorKind.UNARY_OPERATOR 39 19\n",
      "count5 CursorKind.DECL_REF_EXPR 39 19\n",
      " CursorKind.WHILE_STMT 41 23\n",
      " CursorKind.BINARY_OPERATOR 41 29\n",
      "n CursorKind.UNEXPOSED_EXPR 41 29\n",
      "n CursorKind.DECL_REF_EXPR 41 29\n",
      " CursorKind.INTEGER_LITERAL 41 32\n",
      " CursorKind.COMPOUND_STMT 41 34\n",
      " CursorKind.BINARY_OPERATOR 42 19\n",
      "n CursorKind.DECL_REF_EXPR 42 19\n",
      " CursorKind.BINARY_OPERATOR 42 21\n",
      "n CursorKind.UNEXPOSED_EXPR 42 21\n",
      "n CursorKind.DECL_REF_EXPR 42 21\n",
      " CursorKind.INTEGER_LITERAL 42 23\n",
      " CursorKind.UNARY_OPERATOR 43 19\n",
      "count6 CursorKind.DECL_REF_EXPR 43 19\n",
      " CursorKind.RETURN_STMT 46 16\n",
      " CursorKind.INTEGER_LITERAL 46 23\n",
      "B CursorKind.VAR_DECL 49 7\n",
      " CursorKind.UNEXPOSED_EXPR 49 11\n",
      " CursorKind.BINARY_OPERATOR 49 11\n",
      " CursorKind.INTEGER_LITERAL 49 11\n",
      " CursorKind.INTEGER_LITERAL 49 13\n",
      "mainB CursorKind.FUNCTION_DECL 51 5\n",
      " CursorKind.COMPOUND_STMT 52 1\n",
      " CursorKind.DECL_STMT 53 2\n",
      "num CursorKind.VAR_DECL 53 6\n",
      "j CursorKind.VAR_DECL 53 10\n",
      "i CursorKind.VAR_DECL 53 12\n",
      "an CursorKind.VAR_DECL 53 14\n",
      " CursorKind.INTEGER_LITERAL 53 17\n",
      " CursorKind.INIT_LIST_EXPR 53 20\n",
      " CursorKind.INTEGER_LITERAL 53 21\n",
      " CursorKind.INTEGER_LITERAL 53 25\n",
      " CursorKind.INTEGER_LITERAL 53 28\n",
      " CursorKind.INTEGER_LITERAL 53 31\n",
      " CursorKind.INTEGER_LITERAL 53 34\n",
      " CursorKind.INTEGER_LITERAL 53 36\n",
      " CursorKind.FOR_STMT 56 2\n",
      " CursorKind.BINARY_OPERATOR 56 6\n",
      "i CursorKind.DECL_REF_EXPR 56 6\n",
      " CursorKind.INTEGER_LITERAL 56 8\n",
      " CursorKind.BINARY_OPERATOR 56 10\n",
      "i CursorKind.UNEXPOSED_EXPR 56 10\n",
      "i CursorKind.DECL_REF_EXPR 56 10\n",
      " CursorKind.INTEGER_LITERAL 56 12\n",
      " CursorKind.UNARY_OPERATOR 56 14\n",
      "i CursorKind.DECL_REF_EXPR 56 14\n",
      " CursorKind.COMPOUND_STMT 57 2\n",
      " CursorKind.BINARY_OPERATOR 58 2\n",
      "num CursorKind.DECL_REF_EXPR 58 2\n",
      " CursorKind.BINARY_OPERATOR 58 6\n",
      "num CursorKind.UNEXPOSED_EXPR 58 6\n",
      "num CursorKind.DECL_REF_EXPR 58 6\n",
      " CursorKind.BINARY_OPERATOR 58 10\n",
      " CursorKind.BINARY_OPERATOR 58 10\n",
      "num CursorKind.UNEXPOSED_EXPR 58 10\n",
      "num CursorKind.DECL_REF_EXPR 58 10\n",
      " CursorKind.UNEXPOSED_EXPR 58 14\n",
      " CursorKind.ARRAY_SUBSCRIPT_EXPR 58 14\n",
      "an CursorKind.UNEXPOSED_EXPR 58 14\n",
      "an CursorKind.DECL_REF_EXPR 58 14\n",
      " CursorKind.BINARY_OPERATOR 58 17\n",
      "i CursorKind.UNEXPOSED_EXPR 58 17\n",
      "i CursorKind.DECL_REF_EXPR 58 17\n",
      " CursorKind.INTEGER_LITERAL 58 19\n",
      " CursorKind.UNEXPOSED_EXPR 58 22\n",
      " CursorKind.ARRAY_SUBSCRIPT_EXPR 58 22\n",
      "an CursorKind.UNEXPOSED_EXPR 58 22\n",
      "an CursorKind.DECL_REF_EXPR 58 22\n",
      " CursorKind.BINARY_OPERATOR 58 25\n",
      "i CursorKind.UNEXPOSED_EXPR 58 25\n",
      "i CursorKind.DECL_REF_EXPR 58 25\n",
      " CursorKind.INTEGER_LITERAL 58 27\n",
      " CursorKind.RETURN_STMT 61 2\n",
      " CursorKind.INTEGER_LITERAL 61 9\n",
      "C CursorKind.VAR_DECL 63 8\n",
      " CursorKind.UNEXPOSED_EXPR 63 12\n",
      " CursorKind.BINARY_OPERATOR 63 12\n",
      " CursorKind.INTEGER_LITERAL 63 12\n",
      " CursorKind.INTEGER_LITERAL 63 14\n"
     ]
    }
   ],
   "source": [
    "import clang\n",
    "import clang.cindex\n",
    "from clang.cindex import CursorKind\n",
    "\n",
    "#index = clang.cindex.Index.create()\n",
    "#tu = index.parse('test.cpp')\n",
    "\n",
    "def preorder_travers_AST(cursor):\n",
    "    for cur in cursor.get_children():\n",
    "        #do something\n",
    "        print(cur.spelling, cur.kind, cur.location.line, cur.location.column)\n",
    "        #print(cur.spelling, cur.kind == CursorKind.FUNCTION_DECL)\n",
    "        #print(cur.spelling, cur.location.line, cur.location.column)\n",
    "        \n",
    "        #if cur.kind == CursorKind.FUNCTION_DECL:\n",
    "        #    print(\"function: %s, start line: %d, end line: d\" % (cur.spelling, cur.location.line, ))\n",
    "            \n",
    "        \n",
    "        preorder_travers_AST(cur)\n",
    "\n",
    "with open('ast test/cpp test 2.cpp', encoding='utf-8') as f:\n",
    "    code = f.read()\n",
    "    \n",
    "index = clang.cindex.Index.create()\n",
    "tu = index.parse(path='anything.cpp', unsaved_files=[('anything.cpp',code)])\n",
    "#print(tu)\n",
    "#print(tu.spelling, tu.kind, tu.location.line, tu.location.column)\n",
    "\n",
    "AST_root_node = tu.cursor  #cursor根节点\n",
    "#print(AST_root_node)\n",
    "#print(AST_root_node.spelling, AST_root_node.kind, AST_root_node.location.line, AST_root_node.location.column)\n",
    "\n",
    "preorder_travers_AST(AST_root_node)\n",
    "\n",
    "#A = getFunctions(code, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T13:41:03.013082Z",
     "start_time": "2020-12-28T13:41:03.007071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CursorKind.RETURN_STMT"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func0 = [i for i in AST_root_node.get_children()][0]\n",
    "func_body = [i for i in func0.get_children()][0]\n",
    "func1 = func_body.kind\n",
    "[i for i in func_body.get_children()][0].kind\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T12:46:25.483097Z",
     "start_time": "2020-12-28T12:46:25.479108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CursorKind.FUNCTION_DECL"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T07:27:47.712084Z",
     "start_time": "2020-10-11T07:27:47.703080Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mainA', 'mainB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T07:27:47.721033Z",
     "start_time": "2020-10-11T07:27:47.713054Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['FuncDef', 'Decl', 'FuncDecl', 'mainA', 'int', 'Compound', 'Decl', 'n', 'int', 'Decl', 'i', 'int', 'Decl', 'ArrayDecl', 'shuzu', 'int', '111', 'Decl', 'count1', 'int', '0', 'Decl', 'count3', 'int', '0', 'Decl', 'count2', 'int', '0', 'Decl', 'count4', 'int', '0', 'Decl', 'count5', 'int', '0', 'Decl', 'count6', 'int', '0', 'FuncCall', 'scanf', 'ExprList', '\"%d\"', '&', 'n', 'While', '>=', 'n', '100', 'Compound', '=', 'n', '-', 'n', '100', '++', 'count1', 'End', 'While', '>=', 'n', '50', 'Compound', '=', 'n', '-', 'n', '50', '++', 'count2', 'End', 'While', '>=', 'n', '20', 'Compound', '=', 'n', '-', 'n', '20', '++', 'count3', 'End', 'While', '>=', 'n', '10', 'Compound', '=', 'n', '-', 'n', '10', '++', 'count4', 'End', 'While', '>=', 'n', '5', 'Compound', '=', 'n', '-', 'n', '5', '++', 'count5', 'End', 'While', '>=', 'n', '1', 'Compound', '=', 'n', '-', 'n', '1', '++', 'count6', 'End', 'FuncCall', 'printf', 'ExprList', '\"%d\\\\n%d\\\\n%d\\\\n%d\\\\n%d\\\\n%d\"', 'count1', 'count2', 'count3', 'count4', 'count5', 'count6', 'Return', '0', 'End'], ['FuncDef', 'Decl', 'FuncDecl', 'mainB', 'int', 'Compound', 'Decl', 'num', 'int', 'Decl', 'j', 'int', 'Decl', 'i', 'int', 'Decl', 'ArrayDecl', 'an', 'int', '6', 'InitList', '100', '50', '20', '10', '5', '1', '>>', 'cin', 'num', '<<', '<<', 'cout', '/', 'num', 'ArrayRef', 'an', '0', 'endl', 'For', '=', 'i', '1', '<', 'i', '6', '++', 'i', 'Compound', '=', 'num', '-', 'num', '*', '/', 'num', 'ArrayRef', 'an', '-', 'i', '1', 'ArrayRef', 'an', '-', 'i', '1', '<<', '<<', 'cout', '/', 'num', 'ArrayRef', 'an', 'i', 'endl', 'End', 'Return', '0', 'End']]\n"
     ]
    }
   ],
   "source": [
    "print(seqence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T07:27:47.734682Z",
     "start_time": "2020-10-11T07:27:47.723735Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2957, [2957, [2957, [2957, [22]]]]],\n",
       "  [2957],\n",
       "  [2957, [140, [22]]],\n",
       "  [2957, [21, [22]]],\n",
       "  [2957, [2957, [2957, [22]], [2957]]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957, [22]], [18]],\n",
       "  [2957, [2957], [2957, [2957], [156, [140]]]],\n",
       "  [2957, [190, [140], [410]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [410]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957, [190, [140], [1103]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [1103]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957, [190, [140], [655]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [655]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957, [190, [140], [302]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [302]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957, [190, [140], [241]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [241]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957, [190, [140], [26]]],\n",
       "  [2957],\n",
       "  [12, [140], [39, [140], [26]]],\n",
       "  [48, [2957]],\n",
       "  [9],\n",
       "  [2957,\n",
       "   [1643],\n",
       "   [2957, [2957], [2957], [2957], [2957], [2957], [2957], [2957]]],\n",
       "  [2957, [18]],\n",
       "  [9]],\n",
       " [[2957, [2957, [2957, [2957, [22]]]]],\n",
       "  [2957],\n",
       "  [2957, [502, [22]]],\n",
       "  [2957, [68, [22]]],\n",
       "  [2957, [21, [22]]],\n",
       "  [2957,\n",
       "   [2957, [2957, [22]], [324]],\n",
       "   [2957, [410], [1103], [655], [302], [241], [26]]],\n",
       "  [255, [2957], [502]],\n",
       "  [464, [464, [2957], [139, [502], [2957, [2957], [18]]]], [2957]],\n",
       "  [2957, [12, [21], [26]], [47, [21], [324]], [48, [21]]],\n",
       "  [2957],\n",
       "  [12,\n",
       "   [502],\n",
       "   [39,\n",
       "    [502],\n",
       "    [86,\n",
       "     [139, [502], [2957, [2957], [39, [21], [26]]]],\n",
       "     [2957, [2957], [39, [21], [26]]]]]],\n",
       "  [464, [464, [2957], [139, [502], [2957, [2957], [21]]]], [2957]],\n",
       "  [9],\n",
       "  [2957, [18]],\n",
       "  [9]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T07:27:47.748673Z",
     "start_time": "2020-10-11T07:27:47.736677Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['UNKNOWN', ['UNKNOWN', ['UNKNOWN', ['UNKNOWN', ['int']]]]],\n",
       "  ['UNKNOWN'],\n",
       "  ['UNKNOWN', ['n', ['int']]],\n",
       "  ['UNKNOWN', ['i', ['int']]],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['UNKNOWN', ['int']], ['UNKNOWN']]],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN', ['int']], ['0']],\n",
       "  ['UNKNOWN', ['UNKNOWN'], ['UNKNOWN', ['UNKNOWN'], ['&', ['n']]]],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['100']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['100']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['50']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['50']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['20']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['20']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['10']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['10']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['5']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['5']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['>=', ['n'], ['1']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=', ['n'], ['-', ['n'], ['1']]],\n",
       "  ['++', ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN',\n",
       "   ['printf'],\n",
       "   ['UNKNOWN',\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN'],\n",
       "    ['UNKNOWN']]],\n",
       "  ['UNKNOWN', ['0']],\n",
       "  ['End']],\n",
       " [['UNKNOWN', ['UNKNOWN', ['UNKNOWN', ['UNKNOWN', ['int']]]]],\n",
       "  ['UNKNOWN'],\n",
       "  ['UNKNOWN', ['num', ['int']]],\n",
       "  ['UNKNOWN', ['j', ['int']]],\n",
       "  ['UNKNOWN', ['i', ['int']]],\n",
       "  ['UNKNOWN',\n",
       "   ['UNKNOWN', ['UNKNOWN', ['int']], ['6']],\n",
       "   ['UNKNOWN', ['100'], ['50'], ['20'], ['10'], ['5'], ['1']]],\n",
       "  ['>>', ['UNKNOWN'], ['num']],\n",
       "  ['<<',\n",
       "   ['<<', ['UNKNOWN'], ['/', ['num'], ['UNKNOWN', ['UNKNOWN'], ['0']]]],\n",
       "   ['UNKNOWN']],\n",
       "  ['UNKNOWN', ['=', ['i'], ['1']], ['<', ['i'], ['6']], ['++', ['i']]],\n",
       "  ['UNKNOWN'],\n",
       "  ['=',\n",
       "   ['num'],\n",
       "   ['-',\n",
       "    ['num'],\n",
       "    ['*',\n",
       "     ['/', ['num'], ['UNKNOWN', ['UNKNOWN'], ['-', ['i'], ['1']]]],\n",
       "     ['UNKNOWN', ['UNKNOWN'], ['-', ['i'], ['1']]]]]],\n",
       "  ['<<',\n",
       "   ['<<', ['UNKNOWN'], ['/', ['num'], ['UNKNOWN', ['UNKNOWN'], ['i']]]],\n",
       "   ['UNKNOWN']],\n",
       "  ['End'],\n",
       "  ['UNKNOWN', ['0']],\n",
       "  ['End']]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T07:27:47.753630Z",
     "start_time": "2020-10-11T07:27:47.749642Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "int A = 1+2;\n",
      "    \n",
      "int mainA()\n",
      "{\n",
      "    int n,i,shuzu[111],count1=0,count3=0,count2=0,count4=0,count5=0,count6=0;\n",
      "    scanf(\"%d\",&n);\n",
      "    while(n>=100){\n",
      "                  n=n-100;\n",
      "                  count1++;\n",
      "                  }\n",
      "                      while(n>=50){\n",
      "                  n=n-50;\n",
      "                  count2++;\n",
      "                  }\n",
      "                      while(n>=20){\n",
      "                  n=n-20;\n",
      "                  count3++;\n",
      "                  }\n",
      "                      while(n>=10){\n",
      "                  n=n-10;\n",
      "                  count4++;\n",
      "                  }    while(n>=5){\n",
      "                  n=n-5;\n",
      "                  count5++;\n",
      "                  }\n",
      "                      while(n>=1){\n",
      "                  n=n-1;\n",
      "                  count6++;\n",
      "                  }\n",
      "               printf(\"%d\\n%d\\n%d\\n%d\\n%d\\n%d\",count1,count2,count3,count4,count5,count6);\n",
      "               return 0;\n",
      "               }\n",
      "\n",
      "float B = 2/3;\n",
      "\n",
      "int mainB()\n",
      "{\n",
      "\tint num,j,i,an[6]={100,50,20,10,5,1};\n",
      "\tcin>>num;\n",
      "\tcout<<num/an[0]<<endl;\n",
      "\tfor(i=1;i<6;i++)\n",
      "\t{\n",
      "\tnum=num-num/an[i-1]*an[i-1];\n",
      "\tcout<<num/an[i]<<endl;\n",
      "\t}\n",
      "\treturn 0;\n",
      "}\n",
      "double C = 4*5;\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T14:20:54.856171Z",
     "start_time": "2021-01-05T14:20:54.852211Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def expand(nested_list):  # 生成器，用于展开嵌套的list\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            #for sub_item in expand(item):\n",
    "            #    yield sub_item\n",
    "            yield from expand(item)\n",
    "        elif item:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T14:20:34.925774Z",
     "start_time": "2021-01-05T14:20:34.915802Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# For java\n",
    "Logic1 = ['IfStatement', 'ForStatement', 'WhileStatement', 'DoStatement', 'SwitchStatement']\n",
    "Logic2 = ['MethodDeclaration', 'ConstructorDeclaration']\n",
    "\n",
    "class Node_java(object):\n",
    "    def __init__(self, node):\n",
    "        self.node = node\n",
    "        self.is_str = isinstance(self.node, str)  # str => 叶子节点 => 无孩子节点\n",
    "        self.token = self.get_token(node)\n",
    "        self.children = self.add_children()\n",
    "\n",
    "    def is_leaf(self):\n",
    "        if self.is_str:\n",
    "            return True\n",
    "        return len(self.node.children) == 0\n",
    "\n",
    "    def get_token(self, node):\n",
    "        from javalang.ast import Node\n",
    "        if isinstance(node, str):\n",
    "            token = node\n",
    "        elif isinstance(node, set): # 为什么？为什么是set的时候就是Modifier?\n",
    "            token = 'Modifier'  # 访问修饰符，比如 public，private，static\n",
    "        elif isinstance(node, Node):\n",
    "            token = node.__class__.__name__\n",
    "        else:\n",
    "            token = ''\n",
    "        return token\n",
    "\n",
    "    def ori_children(self, root):\n",
    "        from javalang.ast import Node\n",
    "        if isinstance(root, Node):\n",
    "            if self.token in Logic2:  # 这两个比较特殊？\n",
    "                children = root.children[:-1]  # 最后一个丢弃？为什么？最后一个是什么？\n",
    "            else:\n",
    "                children = root.children\n",
    "        elif isinstance(root, set):\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "\n",
    "        return list(expand(children))\n",
    "\n",
    "    def add_children(self):\n",
    "        if self.is_str:  # str => 叶子节点 => 无孩子节点\n",
    "            return []\n",
    "        children = self.ori_children(self.node)\n",
    "        \n",
    "        # 下面是嵌套转化，把所有 javalang.ast.Node 全部转化成 Node_java\n",
    "        if self.token in Logic1:\n",
    "            return [Node_java(children[0])]\n",
    "        elif self.token in Logic2:\n",
    "            return [Node_java(child) for child in children]\n",
    "        else:\n",
    "            return [Node_java(child) for child in children if self.get_token(child) not in Logic1]  # What???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T14:20:39.566156Z",
     "start_time": "2021-01-05T14:20:39.541250Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor_java():\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.max_token = len(vocab)\n",
    "    \n",
    "    '''\n",
    "    以下5个是从file到function_ast，也就是把一个文件中代码解析成AST并拆分出各个函数\n",
    "    '''\n",
    "    def file_to_code(self, filename):\n",
    "        import os\n",
    "        assert os.path.isfile(filename)\n",
    "        assert filename[-5:].lower()=='.java'\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "                code = f.read()\n",
    "            return code\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def file_to_ast(self, file):\n",
    "        ast = self.code_to_ast(self.file_to_code(file))\n",
    "        return ast\n",
    "    \n",
    "    def code_to_ast(self, code):\n",
    "        import javalang\n",
    "        try:\n",
    "            ast = javalang.parse.parse(code)\n",
    "            #seq = trans2tokenseq(ast)\n",
    "            return ast\n",
    "        except:\n",
    "            try:\n",
    "                tokens = javalang.tokenizer.tokenize(code)\n",
    "                parser = javalang.parser.Parser(tokens)\n",
    "                ast = parser.parse_member_declaration()\n",
    "                return ast\n",
    "            except:\n",
    "                return None\n",
    "            \n",
    "    def get_functions(self, ast):\n",
    "        # 提取所有的function\n",
    "        import javalang\n",
    "        fun_list = list(ast.filter(javalang.tree.ConstructorDeclaration))\n",
    "        fun_list.extend(ast.filter(javalang.tree.MethodDeclaration))\n",
    "        return [f[1] for f in fun_list]\n",
    "        # f[0] 好像是 path, f[1] 才是 node\n",
    "\n",
    "    def get_function_name(self, function_ast):\n",
    "        return function_ast.name\n",
    "    \n",
    "    def extract_functions(self, code):\n",
    "        '''\n",
    "        输入代码，输出两个list：一个是函数的ast，一个是函数起止行\n",
    "        '''\n",
    "    \n",
    "        import re\n",
    "        import javalang\n",
    "        import itertools\n",
    "\n",
    "        re_string = re.escape(\"\\\"\") + '.*?' + re.escape(\"\\\"\")\n",
    "\n",
    "        comment_inline_p = '//'\n",
    "        comment_inline = re.escape(comment_inline_p)\n",
    "        comment_inline_pattern = comment_inline + '.*?$'\n",
    "\n",
    "        function_nodes = []\n",
    "        function_pos = []\n",
    "\n",
    "        tree = None\n",
    "\n",
    "        try:\n",
    "            tree = javalang.parse.parse(code)\n",
    "        except Exception as e:\n",
    "            return None, None\n",
    "            #logging.warning(\"File \" + file_path + \" cannot be parsed. (1)\" + str(e))\n",
    "\n",
    "        file_string_split = code.split('\\n')\n",
    "        nodes = itertools.chain(tree.filter(\n",
    "            javalang.tree.ConstructorDeclaration), tree.filter(javalang.tree.MethodDeclaration))\n",
    "\n",
    "        for path, node in nodes:\n",
    "            (start_lineno, b) = node.position\n",
    "            \n",
    "            ##################################\n",
    "            end_lineno = start_lineno\n",
    "            closed = 0\n",
    "            openned = 0\n",
    "\n",
    "            for line in file_string_split[start_lineno-1:]:\n",
    "                if len(line.strip()) == 0:\n",
    "                    continue\n",
    "                \n",
    "                line_re = re.sub(re_string, '', line, flags=re.DOTALL)\n",
    "                # 先删字符串再删注释\n",
    "                line_re = re.sub(comment_inline_pattern, '', line_re, flags=re.MULTILINE)\n",
    "\n",
    "                closed += line_re.count('}')\n",
    "                openned += line_re.count('{')\n",
    "\n",
    "                if closed == openned:\n",
    "                    break\n",
    "                else:\n",
    "                    end_lineno += 1\n",
    "            ###################################\n",
    "\n",
    "            function_pos.append((start_lineno, end_lineno))\n",
    "            function_nodes.append(node)\n",
    "\n",
    "\n",
    "        return function_nodes, function_pos\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    以下两个函数分别获取节点token和孩子节点，是后续其他操作的基础\n",
    "    '''\n",
    "    def get_token(self, node):\n",
    "        from javalang.ast import Node\n",
    "        if isinstance(node, str):\n",
    "            token = node\n",
    "        elif isinstance(node, set):  # 为什么？为什么是set的时候就是Modifier?\n",
    "            token = 'Modifier'#node.pop()\n",
    "        elif isinstance(node, Node):\n",
    "            token = node.__class__.__name__  # 直接用类名\n",
    "        else:\n",
    "            token = ''\n",
    "\n",
    "        return token\n",
    "    \n",
    "    def get_children(self, root):\n",
    "        from javalang.ast import Node\n",
    "        if isinstance(root, Node):\n",
    "            children = root.children\n",
    "        elif isinstance(root, set):  # 按照get_token，这里应该是Modifier，就把Modifier的子节点直接转成list\n",
    "            children = list(root)\n",
    "        else:\n",
    "            children = []\n",
    "\n",
    "        return list(expand(children))\n",
    "    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    以下函数，都是把ast变成ASTNN的输入结构，但是前两个使用token index，后两个使用token本身\n",
    "    主要用前两个\n",
    "    后两个是为了打印出来方便调试\n",
    "    '''\n",
    "    def ast_to_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:  # 这里的每个node就是对应一行代码？\n",
    "            btree = self.replaced_by_index(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_index(self, node):\n",
    "        # 返回的形式：[node, children1, children2, ...]\n",
    "        # 一个大list，每个children又是一个子list\n",
    "        token = node.token\n",
    "        result = [self.vocab[token].index if token in self.vocab else self.max_token]\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_index(child))\n",
    "        return result\n",
    "    \n",
    "    def ast_to_token_block(self, ast):\n",
    "        blocks = []\n",
    "        self.get_blocks(ast, blocks)\n",
    "        tree = []\n",
    "        for node in blocks:\n",
    "            btree = self.replaced_by_token(node)\n",
    "            tree.append(btree)\n",
    "        return tree\n",
    "    \n",
    "    def replaced_by_token(self, node):\n",
    "        result = [node.token if node.token in self.vocab else 'UNKNOWN']\n",
    "        children = node.children\n",
    "        for child in children:\n",
    "            result.append(self.replaced_by_token(child))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    最复杂的东东，根据当前的 node 获得一个或多个 Node_java 并添加到 block_seq 里面\n",
    "    block_seq.append 的必定是一个 Node_java，可以猜测 Node_java 是一个把 javalang.ast.Node 转化成自定义的节点类\n",
    "    '''\n",
    "    def get_blocks(self, node, block_seq):\n",
    "        name, children = self.get_token(node), self.get_children(node)\n",
    "        \n",
    "        # 分4种情况，前3种又进一步对孩子进行细分\n",
    "        if name in Logic2:\n",
    "            block_seq.append(Node_java(node))\n",
    "            body = node.body\n",
    "            for child in body:\n",
    "                if self.get_token(child) not in Logic1 and not hasattr(child, 'block'):\n",
    "                    block_seq.append(Node_java(child))\n",
    "                else:\n",
    "                    self.get_blocks(child, block_seq)\n",
    "                    \n",
    "        elif name in Logic1:\n",
    "            block_seq.append(Node_java(node))\n",
    "            for child in children[1:]:\n",
    "                token = self.get_token(child)\n",
    "                if not hasattr(node, 'block') and token not in Logic1 + ['BlockStatement']:\n",
    "                    block_seq.append(Node_java(child))\n",
    "                else:\n",
    "                    self.get_blocks(child, block_seq)\n",
    "                block_seq.append(Node_java('End'))\n",
    "                \n",
    "        elif name == 'BlockStatement' or hasattr(node, 'block'):\n",
    "            block_seq.append(Node_java(name))\n",
    "            for child in children:\n",
    "                if self.get_token(child) not in Logic1:\n",
    "                    block_seq.append(Node_java(child))\n",
    "                else:\n",
    "                    self.get_blocks(child, block_seq)\n",
    "\n",
    "        else:\n",
    "            for child in children:\n",
    "                self.get_blocks(child, block_seq)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    以下两个函数对ast进行先序遍历获得先序遍历的token序列，用于 word embedding 的训练\n",
    "    '''\n",
    "    def get_sequence(self, node, sequence):  # 获取先序遍历结果，同时为一些特殊代码块加上'End'\n",
    "        token, children = self.get_token(node), self.get_children(node)\n",
    "        sequence.append(token)\n",
    "\n",
    "        for child in children:\n",
    "            self.get_sequence(child, sequence)\n",
    "\n",
    "        if token in Logic1:\n",
    "            sequence.append('End')  \n",
    "            # 因为 Logic1 之后会紧接着一个 'BlockStatement' (表示左大括号)\n",
    "            # 所以在后面要加上一个 'End' (表示右大括号)\n",
    "\n",
    "    def trans_to_sequences(self, ast):\n",
    "        # 这个用于生成token列表，用于 word embedding 的训练\n",
    "        sequence = []\n",
    "        self.get_sequence(ast, sequence)  # 从根节点开始先序遍历\n",
    "        return sequence\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    以下函数待定，只是为了打印出来看一下ast或者block之类的，方便调试\n",
    "    '''\n",
    "    def visit_block(self, block):\n",
    "        pass\n",
    "        \n",
    "    def visit_token_block(self, block):\n",
    "        pass\n",
    "    \n",
    "    def block_to_embedded(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T14:21:01.868044Z",
     "start_time": "2021-01-05T14:21:01.716183Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "root = 'data/'\n",
    "lang = 'java'\n",
    "\n",
    "word2vec = Word2Vec.load(root+lang+\"/train/embedding/node_w2v_128\").wv\n",
    "preprocessor = Preprocessor_java(word2vec.vocab)\n",
    "\n",
    "file_name = 'data/other_java/abdera/adapters/filesystem/src/main/java/org/apache/abdera/protocol/server/adapters/filesystem/FilesystemAdapter.java'\n",
    "file_name = os.path.normpath(file_name)\n",
    "\n",
    "code = preprocessor.file_to_code(file_name)\n",
    "ast = preprocessor.code_to_ast(code)\n",
    "fun_asts = preprocessor.get_functions(ast)\n",
    "fun_names = [preprocessor.get_function_name(f) for f in fun_asts]\n",
    "\n",
    "\n",
    "seqence = [preprocessor.trans_to_sequences(f) for f in fun_asts]\n",
    "blocks = [preprocessor.ast_to_block(f) for f in fun_asts]\n",
    "token_blocks = [preprocessor.ast_to_token_block(f) for f in fun_asts]\n",
    "\n",
    "nodes, pos = preprocessor.extract_functions(code)\n",
    "\n",
    "#embedding_seq = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T12:36:57.173919Z",
     "start_time": "2021-01-05T12:36:57.164942Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 60),\n",
       " (62, 76),\n",
       " (78, 89),\n",
       " (91, 108),\n",
       " (110, 125),\n",
       " (127, 137),\n",
       " (139, 146),\n",
       " (148, 157),\n",
       " (159, 176),\n",
       " (178, 193),\n",
       " (195, 197),\n",
       " (199, 204),\n",
       " (206, 212),\n",
       " (214, 231),\n",
       " (234, 236)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:05:19.754900Z",
     "start_time": "2020-10-10T07:05:19.747922Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MethodDeclaration', 'Modifier', 'private', 'addPagingLinks', 'FormalParameter', 'ReferenceType', 'RequestContext', 'request', 'FormalParameter', 'ReferenceType', 'Feed', 'feed', 'FormalParameter', 'BasicType', 'int', 'currentpage', 'FormalParameter', 'BasicType', 'int', 'count', 'LocalVariableDeclaration', 'ReferenceType', 'Map', 'TypeArgument', 'ReferenceType', 'String', 'TypeArgument', 'ReferenceType', 'Object', 'VariableDeclarator', 'params', 'ClassCreator', 'ReferenceType', 'HashMap', 'TypeArgument', 'ReferenceType', 'String', 'TypeArgument', 'ReferenceType', 'Object', 'StatementExpression', 'MethodInvocation', 'params', 'Literal', '\"count\"', 'MemberReference', 'count', 'put', 'StatementExpression', 'MethodInvocation', 'params', 'Literal', '\"page\"', 'BinaryOperation', '+', 'MemberReference', 'currentpage', 'Literal', '1', 'put', 'LocalVariableDeclaration', 'ReferenceType', 'String', 'VariableDeclarator', 'next', 'MethodInvocation', 'paging_template', 'MemberReference', 'params', 'expand', 'StatementExpression', 'Assignment', 'MemberReference', 'next', 'MethodInvocation', 'request', 'MethodInvocation', 'MemberReference', 'next', 'resolve', 'MethodInvocation', 'toString', 'getResolvedUri', '=', 'StatementExpression', 'MethodInvocation', 'feed', 'MemberReference', 'next', 'Literal', '\"next\"', 'addLink', 'IfStatement', 'BinaryOperation', '>', 'MemberReference', 'currentpage', 'Literal', '0', 'BlockStatement', 'StatementExpression', 'MethodInvocation', 'params', 'Literal', '\"page\"', 'BinaryOperation', '-', 'MemberReference', 'currentpage', 'Literal', '1', 'put', 'LocalVariableDeclaration', 'ReferenceType', 'String', 'VariableDeclarator', 'prev', 'MethodInvocation', 'paging_template', 'MemberReference', 'params', 'expand', 'StatementExpression', 'Assignment', 'MemberReference', 'prev', 'MethodInvocation', 'request', 'MethodInvocation', 'MemberReference', 'prev', 'resolve', 'MethodInvocation', 'toString', 'getResolvedUri', '=', 'StatementExpression', 'MethodInvocation', 'feed', 'MemberReference', 'prev', 'Literal', '\"previous\"', 'addLink', 'End', 'StatementExpression', 'MethodInvocation', 'params', 'Literal', '\"page\"', 'Literal', '0', 'put', 'LocalVariableDeclaration', 'ReferenceType', 'String', 'VariableDeclarator', 'current', 'MethodInvocation', 'paging_template', 'MemberReference', 'params', 'expand', 'StatementExpression', 'Assignment', 'MemberReference', 'current', 'MethodInvocation', 'request', 'MethodInvocation', 'MemberReference', 'current', 'resolve', 'MethodInvocation', 'toString', 'getResolvedUri', '=', 'StatementExpression', 'MethodInvocation', 'feed', 'MemberReference', 'current', 'Literal', '\"current\"', 'addLink']\n"
     ]
    }
   ],
   "source": [
    "print(seqence[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:05:19.772851Z",
     "start_time": "2020-10-10T07:05:19.756894Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addPagingLinks 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[25,\n",
       "  [20, [89]],\n",
       "  [2957],\n",
       "  [19, [4, [2957]], [122]],\n",
       "  [19, [4, [2957]], [2957]],\n",
       "  [19, [15, [22]], [2957]],\n",
       "  [19, [15, [22]], [201]]],\n",
       " [7,\n",
       "  [4, [266], [58, [4, [16]]], [58, [4, [145]]]],\n",
       "  [6, [304], [13, [4, [367], [58, [4, [16]]], [58, [4, [145]]]]]]],\n",
       " [3, [1, [304], [2, [2957]], [0, [201]], [119]]],\n",
       " [3, [1, [304], [2, [2957]], [5, [8], [0, [2957]], [2, [26]]], [119]]],\n",
       " [7, [4, [16]], [6, [188], [1, [2957], [0, [304]], [2957]]]],\n",
       " [3,\n",
       "  [10,\n",
       "   [0, [188]],\n",
       "   [1, [122], [1, [0, [188]], [2238]], [1, [63]], [2957]],\n",
       "   [12]]],\n",
       " [3, [1, [2957], [0, [188]], [2, [2957]], [2957]]],\n",
       " [14, [5, [70], [0, [2957]], [2, [18]]]],\n",
       " [11],\n",
       " [3, [1, [304], [2, [2957]], [5, [39], [0, [2957]], [2, [26]]], [119]]],\n",
       " [7, [4, [16]], [6, [2558], [1, [2957], [0, [304]], [2957]]]],\n",
       " [3,\n",
       "  [10,\n",
       "   [0, [2558]],\n",
       "   [1, [122], [1, [0, [2558]], [2238]], [1, [63]], [2957]],\n",
       "   [12]]],\n",
       " [3, [1, [2957], [0, [2558]], [2, [2957]], [2957]]],\n",
       " [9],\n",
       " [3, [1, [304], [2, [2957]], [2, [18]], [119]]],\n",
       " [7, [4, [16]], [6, [806], [1, [2957], [0, [304]], [2957]]]],\n",
       " [3,\n",
       "  [10,\n",
       "   [0, [806]],\n",
       "   [1, [122], [1, [0, [806]], [2238]], [1, [63]], [2957]],\n",
       "   [12]]],\n",
       " [3, [1, [2957], [0, [806]], [2, [2957]], [2957]]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fun_names[2], len(blocks[2]))\n",
    "blocks[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:05:19.786813Z",
     "start_time": "2020-10-10T07:05:19.775844Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['MethodDeclaration',\n",
       "  ['Modifier', ['private']],\n",
       "  ['UNKNOWN'],\n",
       "  ['FormalParameter', ['ReferenceType', ['UNKNOWN']], ['request']],\n",
       "  ['FormalParameter', ['ReferenceType', ['UNKNOWN']], ['UNKNOWN']],\n",
       "  ['FormalParameter', ['BasicType', ['int']], ['UNKNOWN']],\n",
       "  ['FormalParameter', ['BasicType', ['int']], ['count']]],\n",
       " ['LocalVariableDeclaration',\n",
       "  ['ReferenceType',\n",
       "   ['Map'],\n",
       "   ['TypeArgument', ['ReferenceType', ['String']]],\n",
       "   ['TypeArgument', ['ReferenceType', ['Object']]]],\n",
       "  ['VariableDeclarator',\n",
       "   ['params'],\n",
       "   ['ClassCreator',\n",
       "    ['ReferenceType',\n",
       "     ['HashMap'],\n",
       "     ['TypeArgument', ['ReferenceType', ['String']]],\n",
       "     ['TypeArgument', ['ReferenceType', ['Object']]]]]]],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['params'],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['MemberReference', ['count']],\n",
       "   ['put']]],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['params'],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['BinaryOperation',\n",
       "    ['+'],\n",
       "    ['MemberReference', ['UNKNOWN']],\n",
       "    ['Literal', ['1']]],\n",
       "   ['put']]],\n",
       " ['LocalVariableDeclaration',\n",
       "  ['ReferenceType', ['String']],\n",
       "  ['VariableDeclarator',\n",
       "   ['next'],\n",
       "   ['MethodInvocation',\n",
       "    ['UNKNOWN'],\n",
       "    ['MemberReference', ['params']],\n",
       "    ['UNKNOWN']]]],\n",
       " ['StatementExpression',\n",
       "  ['Assignment',\n",
       "   ['MemberReference', ['next']],\n",
       "   ['MethodInvocation',\n",
       "    ['request'],\n",
       "    ['MethodInvocation', ['MemberReference', ['next']], ['resolve']],\n",
       "    ['MethodInvocation', ['toString']],\n",
       "    ['UNKNOWN']],\n",
       "   ['=']]],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['UNKNOWN'],\n",
       "   ['MemberReference', ['next']],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['UNKNOWN']]],\n",
       " ['IfStatement',\n",
       "  ['BinaryOperation',\n",
       "   ['>'],\n",
       "   ['MemberReference', ['UNKNOWN']],\n",
       "   ['Literal', ['0']]]],\n",
       " ['BlockStatement'],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['params'],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['BinaryOperation',\n",
       "    ['-'],\n",
       "    ['MemberReference', ['UNKNOWN']],\n",
       "    ['Literal', ['1']]],\n",
       "   ['put']]],\n",
       " ['LocalVariableDeclaration',\n",
       "  ['ReferenceType', ['String']],\n",
       "  ['VariableDeclarator',\n",
       "   ['prev'],\n",
       "   ['MethodInvocation',\n",
       "    ['UNKNOWN'],\n",
       "    ['MemberReference', ['params']],\n",
       "    ['UNKNOWN']]]],\n",
       " ['StatementExpression',\n",
       "  ['Assignment',\n",
       "   ['MemberReference', ['prev']],\n",
       "   ['MethodInvocation',\n",
       "    ['request'],\n",
       "    ['MethodInvocation', ['MemberReference', ['prev']], ['resolve']],\n",
       "    ['MethodInvocation', ['toString']],\n",
       "    ['UNKNOWN']],\n",
       "   ['=']]],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['UNKNOWN'],\n",
       "   ['MemberReference', ['prev']],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['UNKNOWN']]],\n",
       " ['End'],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['params'],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['Literal', ['0']],\n",
       "   ['put']]],\n",
       " ['LocalVariableDeclaration',\n",
       "  ['ReferenceType', ['String']],\n",
       "  ['VariableDeclarator',\n",
       "   ['current'],\n",
       "   ['MethodInvocation',\n",
       "    ['UNKNOWN'],\n",
       "    ['MemberReference', ['params']],\n",
       "    ['UNKNOWN']]]],\n",
       " ['StatementExpression',\n",
       "  ['Assignment',\n",
       "   ['MemberReference', ['current']],\n",
       "   ['MethodInvocation',\n",
       "    ['request'],\n",
       "    ['MethodInvocation', ['MemberReference', ['current']], ['resolve']],\n",
       "    ['MethodInvocation', ['toString']],\n",
       "    ['UNKNOWN']],\n",
       "   ['=']]],\n",
       " ['StatementExpression',\n",
       "  ['MethodInvocation',\n",
       "   ['UNKNOWN'],\n",
       "   ['MemberReference', ['current']],\n",
       "   ['Literal', ['UNKNOWN']],\n",
       "   ['UNKNOWN']]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_blocks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T07:05:19.793795Z",
     "start_time": "2020-10-10T07:05:19.789806Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * Licensed to the Apache Software Foundation (ASF) under one or more\n",
      " * contributor license agreements.  The ASF licenses this file to You\n",
      " * under the Apache License, Version 2.0 (the \"License\"); you may not\n",
      " * use this file except in compliance with the License.\n",
      " * You may obtain a copy of the License at\n",
      " *\n",
      " *     http://www.apache.org/licenses/LICENSE-2.0\n",
      " *\n",
      " * Unless required by applicable law or agreed to in writing, software\n",
      " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      " * See the License for the specific language governing permissions and\n",
      " * limitations under the License.  For additional information regarding\n",
      " * copyright in this work, please see the NOTICE file in the top level\n",
      " * directory of this distribution.\n",
      " */\n",
      "package org.apache.abdera.protocol.server.adapters.filesystem;\n",
      "\n",
      "import java.io.File;\n",
      "import java.io.FileInputStream;\n",
      "import java.io.FileOutputStream;\n",
      "import java.io.IOException;\n",
      "import java.util.Arrays;\n",
      "import java.util.Comparator;\n",
      "import java.util.Date;\n",
      "import java.util.HashMap;\n",
      "import java.util.Map;\n",
      "\n",
      "import org.apache.abdera.Abdera;\n",
      "import org.apache.abdera.i18n.templates.Template;\n",
      "import org.apache.abdera.i18n.text.Normalizer;\n",
      "import org.apache.abdera.i18n.text.Sanitizer;\n",
      "import org.apache.abdera.model.Document;\n",
      "import org.apache.abdera.model.Entry;\n",
      "import org.apache.abdera.model.Feed;\n",
      "import org.apache.abdera.model.Link;\n",
      "import org.apache.abdera.protocol.server.ProviderHelper;\n",
      "import org.apache.abdera.protocol.server.RequestContext;\n",
      "import org.apache.abdera.protocol.server.ResponseContext;\n",
      "import org.apache.abdera.protocol.server.Target;\n",
      "import org.apache.abdera.protocol.server.provider.managed.FeedConfiguration;\n",
      "import org.apache.abdera.protocol.server.provider.managed.ManagedCollectionAdapter;\n",
      "\n",
      "/**\n",
      " * Simple Filesystem Adapter that uses a local directory to store Atompub collection entries. As an extension of the\n",
      " * ManagedCollectionAdapter class, the Adapter is intended to be used with implementations of the ManagedProvider and\n",
      " * are configured using /abdera/adapter/*.properties files. The *.properties file MUST specify the fs.root property to\n",
      " * specify the root directory used by the Adapter.\n",
      " */\n",
      "public class FilesystemAdapter extends ManagedCollectionAdapter {\n",
      "\n",
      "    private final File root;\n",
      "    private final static FileSorter sorter = new FileSorter();\n",
      "    private final static Template paging_template = new Template(\"?{-join|&|count,page}\");\n",
      "\n",
      "    public FilesystemAdapter(Abdera abdera, FeedConfiguration config) {\n",
      "        super(abdera, config);\n",
      "        this.root = getRoot();\n",
      "    }\n",
      "\n",
      "    private File getRoot() {\n",
      "        try {\n",
      "            String root = (String)config.getProperty(\"fs.root\");\n",
      "            File file = new File(root);\n",
      "            if (!file.exists())\n",
      "                file.mkdirs();\n",
      "            if (!file.isDirectory())\n",
      "                throw new RuntimeException(\"Root must be a directory\");\n",
      "            return file;\n",
      "        } catch (Exception e) {\n",
      "            if (e instanceof RuntimeException)\n",
      "                throw (RuntimeException)e;\n",
      "            throw new RuntimeException(e);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    private Entry getEntry(File entryFile) {\n",
      "        if (!entryFile.exists() || !entryFile.isFile())\n",
      "            throw new RuntimeException();\n",
      "        try {\n",
      "            FileInputStream fis = new FileInputStream(entryFile);\n",
      "            Document<Entry> doc = abdera.getParser().parse(fis);\n",
      "            Entry entry = doc.getRoot();\n",
      "            return entry;\n",
      "        } catch (Exception e) {\n",
      "            throw new RuntimeException(e);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    private void addPagingLinks(RequestContext request, Feed feed, int currentpage, int count) {\n",
      "        Map<String, Object> params = new HashMap<String, Object>();\n",
      "        params.put(\"count\", count);\n",
      "        params.put(\"page\", currentpage + 1);\n",
      "        String next = paging_template.expand(params);\n",
      "        next = request.getResolvedUri().resolve(next).toString();\n",
      "        feed.addLink(next, \"next\");\n",
      "        if (currentpage > 0) {\n",
      "            params.put(\"page\", currentpage - 1);\n",
      "            String prev = paging_template.expand(params);\n",
      "            prev = request.getResolvedUri().resolve(prev).toString();\n",
      "            feed.addLink(prev, \"previous\");\n",
      "        }\n",
      "        params.put(\"page\", 0);\n",
      "        String current = paging_template.expand(params);\n",
      "        current = request.getResolvedUri().resolve(current).toString();\n",
      "        feed.addLink(current, \"current\");\n",
      "    }\n",
      "\n",
      "    private void getEntries(RequestContext request, Feed feed, File root) {\n",
      "        File[] files = root.listFiles();\n",
      "        Arrays.sort(files, sorter);\n",
      "        int length = ProviderHelper.getPageSize(request, \"count\", 25);\n",
      "        int offset = ProviderHelper.getOffset(request, \"page\", length);\n",
      "        String _page = request.getParameter(\"page\");\n",
      "        int page = (_page != null) ? Integer.parseInt(_page) : 0;\n",
      "        addPagingLinks(request, feed, page, length);\n",
      "        if (offset > files.length)\n",
      "            return;\n",
      "        for (int n = offset; n < offset + length && n < files.length; n++) {\n",
      "            File file = files[n];\n",
      "            Entry entry = getEntry(file);\n",
      "            feed.addEntry((Entry)entry.clone());\n",
      "        }\n",
      "    }\n",
      "\n",
      "    public ResponseContext getFeed(RequestContext request) {\n",
      "        Feed feed = abdera.newFeed();\n",
      "        feed.setId(config.getServerConfiguration().getServerUri() + \"/\" + config.getFeedId());\n",
      "        feed.setTitle(config.getFeedTitle());\n",
      "        feed.addAuthor(config.getFeedAuthor());\n",
      "        feed.addLink(config.getFeedUri());\n",
      "        feed.addLink(config.getFeedUri(), \"self\");\n",
      "        feed.setUpdated(new Date());\n",
      "        getEntries(request, feed, root);\n",
      "        return ProviderHelper.returnBase(feed.getDocument(), 200, null);\n",
      "    }\n",
      "\n",
      "    public ResponseContext deleteEntry(RequestContext request) {\n",
      "        Target target = request.getTarget();\n",
      "        String key = target.getParameter(\"entry\");\n",
      "        File file = getFile(key, false);\n",
      "        if (file.exists())\n",
      "            file.delete();\n",
      "        return ProviderHelper.nocontent();\n",
      "    }\n",
      "\n",
      "    public ResponseContext getEntry(RequestContext request) {\n",
      "        Target target = request.getTarget();\n",
      "        String key = target.getParameter(\"entry\");\n",
      "        File file = getFile(key, false);\n",
      "        Entry entry = getEntry(file);\n",
      "        if (entry != null)\n",
      "            return ProviderHelper.returnBase(entry.getDocument(), 200, null);\n",
      "        else\n",
      "            return ProviderHelper.notfound(request);\n",
      "    }\n",
      "\n",
      "    public ResponseContext postEntry(RequestContext request) {\n",
      "        if (request.isAtom()) {\n",
      "            try {\n",
      "                Entry entry = (Entry)request.getDocument().getRoot().clone();\n",
      "                String key = createKey(request);\n",
      "                setEditDetail(request, entry, key);\n",
      "                File file = getFile(key);\n",
      "                FileOutputStream out = new FileOutputStream(file);\n",
      "                entry.writeTo(out);\n",
      "                String edit = entry.getEditLinkResolvedHref().toString();\n",
      "                return ProviderHelper.returnBase(entry.getDocument(), 201, null).setLocation(edit);\n",
      "            } catch (Exception e) {\n",
      "                return ProviderHelper.badrequest(request);\n",
      "            }\n",
      "        } else {\n",
      "            return ProviderHelper.notsupported(request);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    private void setEditDetail(RequestContext request, Entry entry, String key) throws IOException {\n",
      "        Target target = request.getTarget();\n",
      "        String feed = target.getParameter(\"feed\");\n",
      "        String id = key;\n",
      "        entry.setEdited(new Date());\n",
      "        Link link = entry.getEditLink();\n",
      "        Map<String, Object> params = new HashMap<String, Object>();\n",
      "        params.put(\"feed\", feed);\n",
      "        params.put(\"entry\", id);\n",
      "        String href = request.absoluteUrlFor(\"entry\", params);\n",
      "        if (link == null) {\n",
      "            entry.addLink(href, \"edit\");\n",
      "        } else {\n",
      "            link.setHref(href);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    private File getFile(String key) {\n",
      "        return getFile(key, true);\n",
      "    }\n",
      "\n",
      "    private File getFile(String key, boolean post) {\n",
      "        File file = new File(root, key);\n",
      "        if (post && file.exists())\n",
      "            throw new RuntimeException(\"File exists\");\n",
      "        return file;\n",
      "    }\n",
      "\n",
      "    private String createKey(RequestContext request) throws IOException {\n",
      "        String slug = request.getSlug();\n",
      "        if (slug == null) {\n",
      "            slug = ((Entry)request.getDocument().getRoot()).getTitle();\n",
      "        }\n",
      "        return Sanitizer.sanitize(slug, \"\", true, Normalizer.Form.D);\n",
      "    }\n",
      "\n",
      "    public ResponseContext putEntry(RequestContext request) {\n",
      "        if (request.isAtom()) {\n",
      "            try {\n",
      "                Entry entry = (Entry)request.getDocument().getRoot().clone();\n",
      "                String key = request.getTarget().getParameter(\"entry\");\n",
      "                setEditDetail(request, entry, key);\n",
      "                File file = getFile(key, false);\n",
      "                FileOutputStream out = new FileOutputStream(file);\n",
      "                entry.writeTo(out);\n",
      "                String edit = entry.getEditLinkResolvedHref().toString();\n",
      "                return ProviderHelper.returnBase(entry.getDocument(), 200, null).setLocation(edit);\n",
      "            } catch (Exception e) {\n",
      "                return ProviderHelper.badrequest(request);\n",
      "            }\n",
      "        } else {\n",
      "            return ProviderHelper.notsupported(request);\n",
      "        }\n",
      "    }\n",
      "\n",
      "    private static class FileSorter implements Comparator<File> {\n",
      "        public int compare(File o1, File o2) {\n",
      "            return o1.lastModified() > o2.lastModified() ? -1 : o1.lastModified() < o2.lastModified() ? 1 : 0;\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code)\n",
    "#print(fun_asts[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
